{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20143bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ECE733\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Artifacts: artifacts\\ensemble\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Improved Hybrid VQC Ensemble\n",
    "- Frozen ResNet18 backbone\n",
    "- 512->4 projector (tanh)\n",
    "- 4-qubit VQC (diverse depth & entanglers)\n",
    "- 4->2 linear head (CrossEntropy with label smoothing)\n",
    "- Bagging x5 + Soft-vote (with temperature calibration)\n",
    "- Optional stacking on calibrated logits\n",
    "- Optional feature caching (precompute 512-d features)\n",
    "\"\"\"\n",
    "\n",
    "import os, random, copy\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, RandomSampler, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# --- Quantum ---\n",
    "import pennylane as qml\n",
    "\n",
    "# ----------------------------\n",
    "# Config & global constants\n",
    "# ----------------------------\n",
    "SEED = 123\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "ROOT = Path(\"./\")\n",
    "TRAIN_ROOT = ROOT / \"_bin_dataset\" / \"train\"\n",
    "VAL_ROOT   = ROOT / \"_bin_dataset\" / \"val\"\n",
    "\n",
    "ART_DIR = ROOT / \"artifacts\" / \"ensemble\"\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "N_MODELS = 5\n",
    "N_EPOCHS = 8\n",
    "BATCH_TRAIN = 32\n",
    "BATCH_VAL = 64\n",
    "LABEL_SMOOTH = 0.05\n",
    "USE_FEATURE_CACHE = True\n",
    "CLIP_NORM = 1.0\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Artifacts: {ART_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06eece4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen backbone loaded. Output features: 512\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 1) Load frozen backbone\n",
    "# ----------------------------\n",
    "def load_frozen_backbone() -> nn.Module:\n",
    "    ckpt_backbone = ROOT / \"outputs\" / \"resnet18_backbone_only.pt\"\n",
    "    if not ckpt_backbone.exists():\n",
    "        alt = ROOT / \"resnet18_finetuned.pt\"\n",
    "        if alt.exists():\n",
    "            ckpt_backbone = alt\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Missing backbone weights (resnet18_backbone_only.pt or resnet18_finetuned.pt).\")\n",
    "\n",
    "    backbone = resnet18(weights=None)\n",
    "    state = torch.load(ckpt_backbone, map_location=\"cpu\")\n",
    "    if isinstance(state, dict) and \"state_dict\" in state:\n",
    "        state = state[\"state_dict\"]\n",
    "    # Load, ignore classifier keys\n",
    "    missing, unexpected = backbone.load_state_dict(state, strict=False)\n",
    "    # print(\"missing:\", missing, \"unexpected:\", unexpected)\n",
    "\n",
    "    backbone.fc = nn.Identity()   # remove head\n",
    "    backbone.eval().to(device)\n",
    "    for p in backbone.parameters():\n",
    "        p.requires_grad_(False)\n",
    "    return backbone\n",
    "\n",
    "BACKBONE = load_frozen_backbone()\n",
    "print(\"Frozen backbone loaded. Output features: 512\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Model components\n",
    "# ----------------------------\n",
    "class L512to4(nn.Module):\n",
    "    def __init__(self, in_dim=512, hidden_dim=4):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_dim, hidden_dim)\n",
    "        self.act = nn.Tanh()\n",
    "    def forward(self, z):\n",
    "        return self.act(self.fc(z))\n",
    "\n",
    "# VQC diversity helpers\n",
    "n_qubits = 4\n",
    "from math import pi as PI\n",
    "\n",
    "def make_entangler(kind: str):\n",
    "    if kind == \"ladder\":\n",
    "        return [(1,2), (0,1), (2,3)]\n",
    "    if kind == \"ring\":\n",
    "        return [(0,1), (1,2), (2,3), (3,0)]\n",
    "    # random subset\n",
    "    pairs = [(0,1),(1,2),(2,3),(0,2),(1,3)]\n",
    "    random.shuffle(pairs)\n",
    "    return pairs[:4]\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    def __init__(self, depth=None, pairs=None, pattern=None, shots=None):\n",
    "        super().__init__()\n",
    "        self.depth = int(depth) if depth is not None else random.choice([6])\n",
    "        self.pairs = pairs if pairs is not None else make_entangler(pattern or random.choice([\"ladder\",\"ring\",\"rand\"]))\n",
    "        self.weights = nn.Parameter(0.01 * torch.randn(self.depth, n_qubits))\n",
    "        self.dev = qml.device(\"default.qubit\", wires=n_qubits, shots=shots)\n",
    "\n",
    "        def circuit(x, w):\n",
    "            for q in range(n_qubits):\n",
    "                qml.Hadamard(wires=q)\n",
    "                qml.RY(PI * x[q] / 2.0, wires=q)\n",
    "            for l in range(self.depth):\n",
    "                for q in range(n_qubits):\n",
    "                    qml.RY(w[l, q], wires=q)\n",
    "                for a,b in self.pairs:\n",
    "                    qml.CNOT(wires=[a,b])\n",
    "            return [qml.expval(qml.PauliZ(q)) for q in range(n_qubits)]\n",
    "\n",
    "        self.qnode = qml.QNode(circuit, self.dev, interface=\"torch\", diff_method=\"best\")\n",
    "\n",
    "    def forward(self, x4_batch: torch.Tensor) -> torch.Tensor:\n",
    "        outs = []\n",
    "        for i in range(x4_batch.shape[0]):\n",
    "            y = self.qnode(x4_batch[i], self.weights)\n",
    "            if not isinstance(y, torch.Tensor):\n",
    "                y = torch.stack(y)\n",
    "            outs.append(y)\n",
    "        return torch.stack(outs, dim=0).to(torch.float32)\n",
    "\n",
    "\n",
    "class L4to2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(4, 2)\n",
    "    def forward(self, z4):\n",
    "        return self.fc(z4)\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Accepts either images [B,3,224,224] OR precomputed features [B,512].\n",
    "    \"\"\"\n",
    "    def __init__(self, backbone, proj, q_layer, head):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone    # frozen\n",
    "        self.proj = proj\n",
    "        self.q_layer = q_layer\n",
    "        self.head = head\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2 and x.size(1) == 512:\n",
    "            z512 = x.to(device)  # precomputed\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                z512 = self.backbone(x)\n",
    "        x4 = self.proj(z512)\n",
    "        zq = self.q_layer(x4)\n",
    "        logits = self.head(zq)\n",
    "        return logits\n",
    "\n",
    "def create_new_model(depth=None, pairs=None):\n",
    "    local_backbone = copy.deepcopy(BACKBONE)\n",
    "    proj = L512to4(512, n_qubits)\n",
    "    q_layer = QuantumLayer(depth=depth, pairs=pairs)  # <- can fix shape here\n",
    "    head = L4to2()\n",
    "    return HybridModel(local_backbone, proj, q_layer, head).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a44967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precompute backbone features:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precompute backbone features: 100%|██████████| 8/8 [00:01<00:00,  4.59it/s]\n",
      "Precompute backbone features: 100%|██████████| 2/2 [00:00<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train=480, val=120\n",
      "Created 5 bagged train loaders; 1 validation loader.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 3) Data & transforms\n",
    "# ----------------------------\n",
    "tfm = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(TRAIN_ROOT, transform=tfm)\n",
    "val_ds   = datasets.ImageFolder(VAL_ROOT,   transform=tfm)\n",
    "\n",
    "def precompute_features(dataset) -> TensorDataset:\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_VAL, shuffle=False, num_workers=0)\n",
    "    feats, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, y in tqdm(loader, desc=\"Precompute backbone features\"):\n",
    "            z = BACKBONE(imgs.to(device))     # frozen backbone\n",
    "            feats.append(z.cpu())\n",
    "            labels.append(y)\n",
    "    Z = torch.cat(feats).contiguous()\n",
    "    Y = torch.cat(labels).contiguous()\n",
    "    return TensorDataset(Z, Y)\n",
    "\n",
    "if USE_FEATURE_CACHE:\n",
    "    train_feat = precompute_features(train_ds)\n",
    "    val_feat   = precompute_features(val_ds)\n",
    "    # Bagged loaders from features\n",
    "    n_samples = len(train_feat)\n",
    "    train_loaders = []\n",
    "    for i in range(N_MODELS):\n",
    "        sampler = RandomSampler(train_feat, replacement=True, num_samples=n_samples,\n",
    "                                generator=torch.Generator().manual_seed(SEED + i))\n",
    "        train_loaders.append(DataLoader(train_feat, batch_size=BATCH_TRAIN, sampler=sampler, num_workers=0))\n",
    "    val_loader = DataLoader(val_feat, batch_size=BATCH_VAL, shuffle=False, num_workers=0)\n",
    "else:\n",
    "    # End-to-end (slower)\n",
    "    n_samples = len(train_ds)\n",
    "    train_loaders = []\n",
    "    for i in range(N_MODELS):\n",
    "        sampler = RandomSampler(train_ds, replacement=True, num_samples=n_samples,\n",
    "                                generator=torch.Generator().manual_seed(SEED + i))\n",
    "        train_loaders.append(DataLoader(train_ds, batch_size=BATCH_TRAIN, sampler=sampler, num_workers=0))\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_VAL, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Dataset: train={len(train_ds)}, val={len(val_ds)}\")\n",
    "print(f\"Created {len(train_loaders)} bagged train loaders; 1 validation loader.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab1e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4) Train loop + utilities\n",
    "# ----------------------------\n",
    "def accuracy_from_logits(logits, labels):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == labels).float().mean().item()\n",
    "\n",
    "def run_epoch(model, loader, optimizer, scheduler, ep, train=True):\n",
    "    model.train(train)\n",
    "    loss_sum, correct, total = 0.0, 0, 0\n",
    "    bar = tqdm(loader, desc=f\"Epoch {ep:02d} ({'Train' if train else 'Val'})\")\n",
    "    crit = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTH if train else 0.0)\n",
    "    for xb, yb in bar:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.q_layer.parameters(), CLIP_NORM)\n",
    "            optimizer.step()\n",
    "        loss_sum += loss.item() * xb.size(0)\n",
    "        acc = (logits.argmax(1) == yb).sum().item()\n",
    "        correct += acc\n",
    "        total += xb.size(0)\n",
    "        bar.set_postfix(loss=loss_sum/total, acc=correct/total)\n",
    "    if train and scheduler is not None:\n",
    "        scheduler.step()\n",
    "    return loss_sum/total, correct/total\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_logits(model, loader) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    all_logits, all_y = [], []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_y.append(yb)\n",
    "    return torch.cat(all_logits), torch.cat(all_y)\n",
    "\n",
    "# Temperature calibration per model on the validation set\n",
    "class TempScale(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.t = nn.Parameter(torch.ones(1))\n",
    "    def forward(self, logits):\n",
    "        return logits / self.t.clamp_min(1e-3)\n",
    "\n",
    "def fit_temperature(model, val_loader) -> float:\n",
    "    model.eval()\n",
    "    logits, y = collect_logits(model, val_loader)\n",
    "    ts = TempScale().to(logits.device)\n",
    "    opt = torch.optim.Adam(ts.parameters(), lr=0.05)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    for _ in range(300):\n",
    "        opt.zero_grad()\n",
    "        loss = crit(ts(logits), y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return float(ts.t.detach().cpu().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a686518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for 5 models...\n",
      "\n",
      "==============================\n",
      "Training Model 1/5\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01 (Train): 100%|██████████| 15/15 [00:26<00:00,  1.75s/it, acc=0.912, loss=0.391]\n",
      "Epoch 01 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.71s/it, acc=0.983, loss=0.209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 1 Ep 01] Train L/A: 0.3906/0.912 | Val L/A: 0.2088/0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02 (Train): 100%|██████████| 15/15 [00:25<00:00,  1.69s/it, acc=0.996, loss=0.199]\n",
      "Epoch 02 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.67s/it, acc=0.983, loss=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 1 Ep 02] Train L/A: 0.1990/0.996 | Val L/A: 0.1509/0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03 (Train): 100%|██████████| 15/15 [00:26<00:00,  1.77s/it, acc=1, loss=0.176]\n",
      "Epoch 03 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.61s/it, acc=0.992, loss=0.139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 1 Ep 03] Train L/A: 0.1759/1.000 | Val L/A: 0.1386/0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04 (Train): 100%|██████████| 15/15 [00:28<00:00,  1.93s/it, acc=1, loss=0.168]\n",
      "Epoch 04 (Val): 100%|██████████| 2/2 [00:04<00:00,  2.06s/it, acc=0.992, loss=0.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 1 Ep 04] Train L/A: 0.1683/1.000 | Val L/A: 0.1296/0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05 (Train): 100%|██████████| 15/15 [00:26<00:00,  1.76s/it, acc=0.998, loss=0.165]\n",
      "Epoch 05 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.56s/it, acc=0.992, loss=0.124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 1 Ep 05] Train L/A: 0.1651/0.998 | Val L/A: 0.1240/0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06 (Train): 100%|██████████| 15/15 [00:25<00:00,  1.70s/it, acc=1, loss=0.158]\n",
      "Epoch 06 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.55s/it, acc=0.992, loss=0.121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 1 Ep 06] Train L/A: 0.1580/1.000 | Val L/A: 0.1211/0.992\n",
      "Early stopping.\n",
      "Saved best weights to artifacts\\ensemble\\model_0.pt\n",
      "Saved model cfg to artifacts\\ensemble\\model_0_cfg.pt: depth=6, pairs=[(0, 1), (1, 2), (2, 3), (3, 0)]\n",
      "Calibrated temperature t=0.457 saved.\n",
      "\n",
      "==============================\n",
      "Training Model 2/5\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01 (Train): 100%|██████████| 15/15 [00:26<00:00,  1.78s/it, acc=0.89, loss=0.36]  \n",
      "Epoch 01 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.61s/it, acc=0.992, loss=0.251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 2 Ep 01] Train L/A: 0.3600/0.890 | Val L/A: 0.2511/0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02 (Train): 100%|██████████| 15/15 [00:26<00:00,  1.75s/it, acc=0.996, loss=0.267]\n",
      "Epoch 02 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.77s/it, acc=0.992, loss=0.224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 2 Ep 02] Train L/A: 0.2673/0.996 | Val L/A: 0.2237/0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03 (Train): 100%|██████████| 15/15 [00:28<00:00,  1.91s/it, acc=0.998, loss=0.251]\n",
      "Epoch 03 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.66s/it, acc=0.992, loss=0.204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 2 Ep 03] Train L/A: 0.2513/0.998 | Val L/A: 0.2042/0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04 (Train): 100%|██████████| 15/15 [00:31<00:00,  2.10s/it, acc=1, loss=0.226]\n",
      "Epoch 04 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.72s/it, acc=0.992, loss=0.192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 2 Ep 04] Train L/A: 0.2261/1.000 | Val L/A: 0.1918/0.992\n",
      "Early stopping.\n",
      "Saved best weights to artifacts\\ensemble\\model_1.pt\n",
      "Saved model cfg to artifacts\\ensemble\\model_1_cfg.pt: depth=6, pairs=[(0, 1), (1, 2), (2, 3), (3, 0)]\n",
      "Calibrated temperature t=0.282 saved.\n",
      "\n",
      "==============================\n",
      "Training Model 3/5\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01 (Train): 100%|██████████| 15/15 [00:26<00:00,  1.75s/it, acc=0.883, loss=0.438]\n",
      "Epoch 01 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.53s/it, acc=0.983, loss=0.307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 3 Ep 01] Train L/A: 0.4381/0.883 | Val L/A: 0.3072/0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02 (Train): 100%|██████████| 15/15 [00:26<00:00,  1.76s/it, acc=1, loss=0.311]\n",
      "Epoch 02 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.57s/it, acc=0.983, loss=0.281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 3 Ep 02] Train L/A: 0.3110/1.000 | Val L/A: 0.2809/0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03 (Train): 100%|██████████| 15/15 [00:26<00:00,  1.80s/it, acc=1, loss=0.288]\n",
      "Epoch 03 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.53s/it, acc=0.983, loss=0.259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 3 Ep 03] Train L/A: 0.2879/1.000 | Val L/A: 0.2592/0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04 (Train): 100%|██████████| 15/15 [00:26<00:00,  1.77s/it, acc=1, loss=0.269]\n",
      "Epoch 04 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.73s/it, acc=0.983, loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 3 Ep 04] Train L/A: 0.2694/1.000 | Val L/A: 0.2438/0.983\n",
      "Early stopping.\n",
      "Saved best weights to artifacts\\ensemble\\model_2.pt\n",
      "Saved model cfg to artifacts\\ensemble\\model_2_cfg.pt: depth=6, pairs=[(1, 2), (0, 1), (2, 3)]\n",
      "Calibrated temperature t=0.280 saved.\n",
      "\n",
      "==============================\n",
      "Training Model 4/5\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01 (Train): 100%|██████████| 15/15 [00:27<00:00,  1.85s/it, acc=0.952, loss=0.327]\n",
      "Epoch 01 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.69s/it, acc=0.983, loss=0.195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 4 Ep 01] Train L/A: 0.3268/0.952 | Val L/A: 0.1947/0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02 (Train): 100%|██████████| 15/15 [00:29<00:00,  1.94s/it, acc=0.992, loss=0.22] \n",
      "Epoch 02 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.95s/it, acc=0.992, loss=0.176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 4 Ep 02] Train L/A: 0.2202/0.992 | Val L/A: 0.1757/0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03 (Train): 100%|██████████| 15/15 [00:29<00:00,  1.94s/it, acc=0.998, loss=0.196]\n",
      "Epoch 03 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.88s/it, acc=0.992, loss=0.161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 4 Ep 03] Train L/A: 0.1963/0.998 | Val L/A: 0.1614/0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04 (Train): 100%|██████████| 15/15 [00:28<00:00,  1.93s/it, acc=0.998, loss=0.191]\n",
      "Epoch 04 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.69s/it, acc=0.992, loss=0.152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 4 Ep 04] Train L/A: 0.1911/0.998 | Val L/A: 0.1522/0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05 (Train): 100%|██████████| 15/15 [00:32<00:00,  2.19s/it, acc=0.998, loss=0.184]\n",
      "Epoch 05 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.77s/it, acc=0.992, loss=0.146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 4 Ep 05] Train L/A: 0.1835/0.998 | Val L/A: 0.1462/0.992\n",
      "Early stopping.\n",
      "Saved best weights to artifacts\\ensemble\\model_3.pt\n",
      "Saved model cfg to artifacts\\ensemble\\model_3_cfg.pt: depth=6, pairs=[(0, 1), (1, 2), (2, 3), (3, 0)]\n",
      "Calibrated temperature t=0.369 saved.\n",
      "\n",
      "==============================\n",
      "Training Model 5/5\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01 (Train): 100%|██████████| 15/15 [00:28<00:00,  1.93s/it, acc=0.779, loss=0.46] \n",
      "Epoch 01 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.67s/it, acc=0.983, loss=0.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 5 Ep 01] Train L/A: 0.4604/0.779 | Val L/A: 0.2598/0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02 (Train): 100%|██████████| 15/15 [00:28<00:00,  1.92s/it, acc=0.994, loss=0.271]\n",
      "Epoch 02 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.80s/it, acc=0.992, loss=0.234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 5 Ep 02] Train L/A: 0.2715/0.994 | Val L/A: 0.2336/0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03 (Train): 100%|██████████| 15/15 [00:29<00:00,  1.94s/it, acc=0.998, loss=0.248]\n",
      "Epoch 03 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.95s/it, acc=0.992, loss=0.214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 5 Ep 03] Train L/A: 0.2482/0.998 | Val L/A: 0.2139/0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04 (Train): 100%|██████████| 15/15 [00:30<00:00,  2.02s/it, acc=0.998, loss=0.235]\n",
      "Epoch 04 (Val): 100%|██████████| 2/2 [00:03<00:00,  1.84s/it, acc=0.992, loss=0.202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 5 Ep 04] Train L/A: 0.2353/0.998 | Val L/A: 0.2020/0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05 (Train): 100%|██████████| 15/15 [00:38<00:00,  2.55s/it, acc=1, loss=0.223]\n",
      "Epoch 05 (Val): 100%|██████████| 2/2 [00:04<00:00,  2.24s/it, acc=0.992, loss=0.194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 5 Ep 05] Train L/A: 0.2228/1.000 | Val L/A: 0.1941/0.992\n",
      "Early stopping.\n",
      "Saved best weights to artifacts\\ensemble\\model_4.pt\n",
      "Saved model cfg to artifacts\\ensemble\\model_4_cfg.pt: depth=6, pairs=[(0, 1), (1, 2), (2, 3), (3, 0)]\n",
      "Calibrated temperature t=0.319 saved.\n",
      "\n",
      "Ensemble training complete.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5) Train ensemble\n",
    "# ----------------------------\n",
    "print(f\"\\nStarting training for {N_MODELS} models...\")\n",
    "cal_temps = []  # temperature per model for calibration\n",
    "\n",
    "for k in range(N_MODELS):\n",
    "    print(f\"\\n{'='*30}\\nTraining Model {k+1}/{N_MODELS}\\n{'='*30}\")\n",
    "    torch.manual_seed(SEED + k)\n",
    "    model_k = create_new_model()\n",
    "\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {\"params\": model_k.proj.parameters(), \"lr\": 1e-3},\n",
    "        {\"params\": model_k.q_layer.parameters(), \"lr\": 1e-2},\n",
    "        {\"params\": model_k.head.parameters(), \"lr\": 1e-3},\n",
    "    ])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "\n",
    "    train_loader_k = train_loaders[k]\n",
    "\n",
    "    best_va, best_sd = -1.0, None\n",
    "    patience, bad = 3, 0\n",
    "\n",
    "    for ep in range(1, N_EPOCHS + 1):\n",
    "        trL, trA = run_epoch(model_k, train_loader_k, optimizer, scheduler, ep, train=True)\n",
    "        vaL, vaA = run_epoch(model_k, val_loader, optimizer, scheduler, ep, train=False)\n",
    "        print(f\"[Model {k+1} Ep {ep:02d}] Train L/A: {trL:.4f}/{trA:.3f} | Val L/A: {vaL:.4f}/{vaA:.3f}\")\n",
    "        if vaA > best_va:\n",
    "            best_va = vaA\n",
    "            best_sd = copy.deepcopy(model_k.state_dict())\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    save_path = ART_DIR / f\"model_{k}.pt\"\n",
    "    if best_sd is not None:\n",
    "        torch.save(best_sd, save_path)\n",
    "        print(f\"Saved best weights to {save_path}\")\n",
    "    # Save best checkpoint\n",
    "    # after torch.save(best_sd, save_path)\n",
    "    cfg_path = ART_DIR / f\"model_{k}_cfg.pt\"\n",
    "    torch.save({\"depth\": model_k.q_layer.depth, \"pairs\": model_k.q_layer.pairs}, cfg_path)\n",
    "    print(f\"Saved model cfg to {cfg_path}: depth={model_k.q_layer.depth}, pairs={model_k.q_layer.pairs}\")\n",
    "\n",
    "\n",
    "    # Temperature calibration on validation set\n",
    "    t_k = fit_temperature(model_k, val_loader)\n",
    "    cal_temps.append(t_k)\n",
    "    torch.save({\"temperature\": t_k}, ART_DIR / f\"model_{k}_temp.pt\")\n",
    "    print(f\"Calibrated temperature t={t_k:.3f} saved.\")\n",
    "\n",
    "print(\"\\nEnsemble training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0110ae62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 base models for ensemble.\n",
      "\n",
      "[Soft-vote] 1.jpg: Positive  (conf 0.7348)\n",
      "Creating meta-dataset (calibrated logits on validation set)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-features: 100%|██████████| 2/2 [00:22<00:00, 11.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training meta-learner on calibrated logits...\n",
      "[Meta Ep 01] loss=0.3625\n",
      "[Meta Ep 02] loss=0.3373\n",
      "[Meta Ep 04] loss=0.2905\n",
      "[Meta Ep 06] loss=0.2509\n",
      "[Meta Ep 08] loss=0.2182\n",
      "[Meta Ep 10] loss=0.1907\n",
      "Meta-learner saved.\n",
      "\n",
      "[Stacked]  1.jpg: Positive  (conf 0.6601)\n"
     ]
    }
   ],
   "source": [
    "def load_base_models():\n",
    "    models, temps = [], []\n",
    "    for k in range(N_MODELS):\n",
    "        path = ART_DIR / f\"model_{k}.pt\"\n",
    "        if not path.exists():\n",
    "            print(f\"Missing {path}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 1) peek state_dict to recover depth from q_layer.weights shape\n",
    "        sd = torch.load(path, map_location=\"cpu\")\n",
    "        if \"q_layer.weights\" in sd:\n",
    "            depth = sd[\"q_layer.weights\"].shape[0]\n",
    "        else:\n",
    "            depth = next(v.shape[0] for k2, v in sd.items() if k2.endswith(\"q_layer.weights\"))\n",
    "\n",
    "        # 2) try to read saved entangler pairs\n",
    "        cfg_path = ART_DIR / f\"model_{k}_cfg.pt\"\n",
    "        pairs = None\n",
    "        if cfg_path.exists():\n",
    "            cfg = torch.load(cfg_path, map_location=\"cpu\")\n",
    "            pairs = cfg.get(\"pairs\", None)\n",
    "\n",
    "        # 3) instantiate with matching depth/pairs, then load\n",
    "        m = create_new_model(depth=depth, pairs=pairs)\n",
    "        m.load_state_dict(sd, strict=True)\n",
    "        m.eval().to(device)\n",
    "        models.append(m)\n",
    "\n",
    "        # load temperature if present\n",
    "        tpath = ART_DIR / f\"model_{k}_temp.pt\"\n",
    "        if tpath.exists():\n",
    "            temps.append(float(torch.load(tpath, map_location=\"cpu\")[\"temperature\"]))\n",
    "        else:\n",
    "            temps.append(1.0)\n",
    "    return models, temps\n",
    "\n",
    "\n",
    "base_models, base_temps = load_base_models()\n",
    "print(f\"Loaded {len(base_models)} base models for ensemble.\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_soft_vote(x, models_list, temps_list, return_probs=False):\n",
    "    \"\"\"x: image tensor [1,3,224,224] or features [1,512]\"\"\"\n",
    "    probs = []\n",
    "    for m, t in zip(models_list, temps_list):\n",
    "        logits = m(x.to(device)) / max(t, 1e-3)\n",
    "        probs.append(F.softmax(logits, dim=1))\n",
    "    avg = torch.mean(torch.stack(probs), dim=0)\n",
    "    pred_idx = int(avg.argmax(dim=1).item())\n",
    "    conf = float(avg.max(dim=1).values.item())\n",
    "    if return_probs:\n",
    "        return pred_idx, conf, avg.cpu().numpy()\n",
    "    return pred_idx, conf\n",
    "\n",
    "# Quick single-image test\n",
    "TEST_IMG = ROOT / \"test1\" / \"1.jpg\"\n",
    "if TEST_IMG.exists() and len(base_models) > 0:\n",
    "    from PIL import Image\n",
    "    tf_single = tfm\n",
    "    img = Image.open(TEST_IMG).convert(\"RGB\")\n",
    "    xb = tf_single(img).unsqueeze(0)\n",
    "    pred_idx, conf, avg_probs = predict_soft_vote(xb, base_models, base_temps, True)\n",
    "    classes = val_ds.classes\n",
    "    print(f\"\\n[Soft-vote] {TEST_IMG.name}: {classes[pred_idx]}  (conf {conf:.4f})\")\n",
    "    # print(\"avg probs:\", avg_probs)\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Stacking on calibrated logits\n",
    "# ----------------------------\n",
    "@torch.no_grad()\n",
    "def create_meta_dataset(models_list, temps_list, loader) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    print(\"Creating meta-dataset (calibrated logits on validation set)...\")\n",
    "    Xs, Ys = [], []\n",
    "    for xb, yb in tqdm(loader, desc=\"Meta-features\"):\n",
    "        xb = xb.to(device)\n",
    "        per_model = []\n",
    "        for m, t in zip(models_list, temps_list):\n",
    "            l = m(xb) / max(t, 1e-3)       # calibrated logits\n",
    "            per_model.append(l)            # [B,2]\n",
    "        Xb = torch.cat(per_model, dim=1)   # [B, 2*N_MODELS]\n",
    "        Xs.append(Xb.cpu())\n",
    "        Ys.append(yb.cpu())\n",
    "    return torch.cat(Xs), torch.cat(Ys)\n",
    "\n",
    "if len(base_models) > 0:\n",
    "    X_meta, y_meta = create_meta_dataset(base_models, base_temps, val_loader)\n",
    "    meta_ds = TensorDataset(X_meta, y_meta)\n",
    "    meta_loader = DataLoader(meta_ds, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "    meta_learner = nn.Linear(2 * len(base_models), 2).to(device)\n",
    "    opt_meta = torch.optim.Adam(meta_learner.parameters(), lr=1e-3)\n",
    "    crit_meta = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"Training meta-learner on calibrated logits...\")\n",
    "    meta_learner.train()\n",
    "    for ep in range(1, 11):\n",
    "        loss_sum, n = 0.0, 0\n",
    "        for Xb, yb in meta_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            opt_meta.zero_grad(set_to_none=True)\n",
    "            out = meta_learner(Xb)\n",
    "            loss = crit_meta(out, yb)\n",
    "            loss.backward()\n",
    "            opt_meta.step()\n",
    "            loss_sum += loss.item() * Xb.size(0); n += Xb.size(0)\n",
    "        if ep == 1 or ep % 2 == 0:\n",
    "            print(f\"[Meta Ep {ep:02d}] loss={loss_sum/n:.4f}\")\n",
    "    meta_learner.eval()\n",
    "    torch.save(meta_learner.state_dict(), ART_DIR / \"meta_learner.pt\")\n",
    "    print(\"Meta-learner saved.\")\n",
    "\n",
    "    class StackedEnsemble(nn.Module):\n",
    "        def __init__(self, bases, temps, meta):\n",
    "            super().__init__()\n",
    "            self.bases = nn.ModuleList(bases)\n",
    "            for m in self.bases:\n",
    "                for p in m.parameters(): p.requires_grad = False\n",
    "            self.temps = [float(t) for t in temps]\n",
    "            self.meta = meta.eval()\n",
    "        @torch.no_grad()\n",
    "        def forward(self, x):\n",
    "            feats = []\n",
    "            for m, t in zip(self.bases, self.temps):\n",
    "                l = m(x.to(device)) / max(t, 1e-3)\n",
    "                feats.append(l)\n",
    "            meta_in = torch.cat(feats, dim=1)\n",
    "            return self.meta(meta_in)\n",
    "\n",
    "    stacked = StackedEnsemble(base_models, base_temps, meta_learner).to(device)\n",
    "\n",
    "    # Optional single-image check\n",
    "    if TEST_IMG.exists():\n",
    "        from PIL import Image\n",
    "        xb = tfm(Image.open(TEST_IMG).convert(\"RGB\")).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            logits = stacked(xb)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            pred = int(probs.argmax(1).item()); conf = float(probs.max(1).values.item())\n",
    "        print(f\"\\n[Stacked]  {TEST_IMG.name}: {val_ds.classes[pred]}  (conf {conf:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
