{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c917249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inference helper (binary & multiclass) ---\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from typing import List\n",
    "\n",
    "# Device configuration\n",
    "def device_auto() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = device_auto()\n",
    "\n",
    "# ImageNet normalization\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Load the saved model\n",
    "def load_trained_model(model_path: str, num_classes: int) -> nn.Module:\n",
    "    \"\"\"Load the trained model from checkpoint\"\"\"\n",
    "    # Rebuild the model architecture\n",
    "    model = models.resnet18(weights=None)\n",
    "    in_feats = model.fc.in_features\n",
    "    \n",
    "    # Recreate the same head structure used during training\n",
    "    if num_classes == 2:\n",
    "        model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, 1))\n",
    "    else:\n",
    "        model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, num_classes))\n",
    "    \n",
    "    # Load the saved weights\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Transformation for inference\n",
    "infer_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Ensure image is 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "def predict_image(model: nn.Module, img_path: str, classes: List[str]) -> dict:\n",
    "    \"\"\"Predict class for a single image using the trained model\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = infer_tfms(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Prediction\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        \n",
    "        if len(classes) == 2:\n",
    "            # Binary classification\n",
    "            p = torch.sigmoid(logits).item()\n",
    "            pred_idx = int(p >= 0.5)\n",
    "            return {\n",
    "                \"pred_idx\": pred_idx, \n",
    "                \"pred_class\": classes[pred_idx], \n",
    "                \"prob_positive\": float(p),\n",
    "                \"prob_negative\": float(1 - p)\n",
    "            }\n",
    "        else:\n",
    "            # Multi-class classification\n",
    "            probs = torch.softmax(logits, dim=1).squeeze(0)\n",
    "            pred_idx = int(probs.argmax().item())\n",
    "            prob_dict = {classes[i]: float(probs[i]) for i in range(len(classes))}\n",
    "            \n",
    "            return {\n",
    "                \"pred_idx\": pred_idx, \n",
    "                \"pred_class\": classes[pred_idx], \n",
    "                \"probabilities\": prob_dict,\n",
    "                \"confidence\": float(probs[pred_idx])\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "394989e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_idx': 1, 'pred_class': 'Positive', 'prob_positive': 1.0, 'prob_negative': 0.0}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"outputs/resnet18_finetuned_with_head.pt\"\n",
    "CLASSES = ['Negative', 'Positive']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "# Load model once\n",
    "model = load_trained_model(MODEL_PATH, NUM_CLASSES)\n",
    "\n",
    "# Predict on an image\n",
    "result = predict_image(model, \"test1/7.jpg\", CLASSES)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# --- Quantum Imports ---\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "\n",
    "# --- 1. Define Model Architecture & Constants ---\n",
    "\n",
    "# Model structure constants\n",
    "n_qubits = 4\n",
    "n_layers = 6\n",
    "\n",
    "# Preprocessing constants\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# PennyLane device\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# --- Class definition for L512to4 ---\n",
    "class L512to4(nn.Module):\n",
    "    def __init__(self, in_dim=512, hidden_dim=4):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_dim, hidden_dim)\n",
    "        self.act = nn.Tanh()\n",
    "    def forward(self, z):\n",
    "        return self.act(self.fc(z))\n",
    "\n",
    "# --- Quantum block definitions---\n",
    "def entangle_ladder():\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_block(x, weights):\n",
    "    for q in range(n_qubits):\n",
    "        qml.Hadamard(wires=q)\n",
    "        qml.RY(pnp.pi * x[q] / 2.0, wires=q)\n",
    "    for l in range(n_layers):\n",
    "        for q in range(n_qubits):\n",
    "            qml.RY(weights[l, q], wires=q)\n",
    "        entangle_ladder()\n",
    "    return [qml.expval(qml.PauliZ(q)) for q in range(n_qubits)]\n",
    "\n",
    "# --- Class definition for QuantumLayer---\n",
    "class QuantumLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Initial value doesn't matter, it will be overwritten\n",
    "        w0 = 0.01 * torch.randn(n_layers, n_qubits)\n",
    "        self.weights = nn.Parameter(w0)\n",
    "    def forward(self, x4_batch):\n",
    "        outs = []\n",
    "        for i in range(x4_batch.shape[0]):\n",
    "            y = quantum_block(x4_batch[i], self.weights)\n",
    "            y = torch.stack(y)\n",
    "            outs.append(y)\n",
    "        zq = torch.stack(outs, dim=0)\n",
    "        zq = zq.to(torch.float32)\n",
    "        return zq\n",
    "\n",
    "# --- Class definition for L4to2---\n",
    "class L4to2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(4, 2)\n",
    "    def forward(self, z4):\n",
    "        return self.fc(z4)\n",
    "\n",
    "# --- Class definition for HybridModel---\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, backbone, proj, q_layer, head):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.proj = proj\n",
    "        self.q_layer = q_layer\n",
    "        self.head = head\n",
    "    def forward(self, imgs):\n",
    "        with torch.no_grad():\n",
    "            z512 = self.backbone(imgs)\n",
    "        x4 = self.proj(z512)\n",
    "        zq = self.q_layer(x4)\n",
    "        logits = self.head(zq)\n",
    "        return logits\n",
    "\n",
    "# --- 2. Define Inference Function---\n",
    "\n",
    "# Preprocessing transforms\n",
    "infer_tf = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# Prediction function\n",
    "@torch.no_grad()\n",
    "def predict_one_with_model(img_path: str, model_for_infer: torch.nn.Module, class_names=None):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = infer_tf(img).unsqueeze(0).to(device)\n",
    "\n",
    "    logits = model_for_infer(x)\n",
    "\n",
    "    # Use the class names from the checkpoint if available, otherwise default\n",
    "    if class_names is None:\n",
    "        class_names = [f\"class{i}\" for i in range(logits.shape[1])]\n",
    "\n",
    "    # binary or multi-class friendly\n",
    "    if logits.shape[1] == 1:\n",
    "        p1 = torch.sigmoid(logits[:, 0])\n",
    "        probs = torch.stack([1 - p1, p1], dim=1)\n",
    "    else:\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "    probs = probs.squeeze(0).cpu()\n",
    "    pred_idx = int(probs.argmax().item())\n",
    "\n",
    "    print(f\"Image: {img_path}\")\n",
    "    print(f\"Prediction: {class_names[pred_idx]} (idx={pred_idx})\")\n",
    "    for i, p in enumerate(probs.tolist()):\n",
    "        print(f\"  {class_names[i]:>12s}: {p:.4f}\")\n",
    "\n",
    "    return {\"label\": class_names[pred_idx], \"index\": pred_idx, \"probs\": probs.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30027946",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"artifacts/hybrid_qml_best.pt\"\n",
    "TEST_IMG = \"test1/1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82468533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Rebuilding hybrid model architecture...\n",
      "Loading weights from: artifacts/hybrid_qml_best.pt\n",
      "Model loaded successfully.\n",
      "Image: test1/1.jpg\n",
      "Prediction: negative (idx=0)\n",
      "      negative: 0.7607\n",
      "      positive: 0.2393\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Using device: {device}\")\n",
    "if not Path(CHECKPOINT_PATH).exists():\n",
    "    print(f\"Error: Checkpoint file not found at {CHECKPOINT_PATH}\")\n",
    "    print(\"Please run the training notebook first to create this file.\")\n",
    "elif not Path(TEST_IMG).exists():\n",
    "    print(f\"Error: Test image not found at {TEST_IMG}\")\n",
    "else:\n",
    "    try:\n",
    "        # 1. Rebuild the SAME hybrid architecture\n",
    "        print(\"Rebuilding hybrid model architecture...\")\n",
    "        backbone = resnet18(weights=None)\n",
    "        backbone.fc = torch.nn.Identity() # Remove classifier head\n",
    "        \n",
    "        proj = L512to4(in_dim=512, hidden_dim=n_qubits)\n",
    "        q_layer = QuantumLayer()\n",
    "        head = L4to2() # Outputs 2 classes\n",
    "        \n",
    "        model_inf = HybridModel(backbone, proj, q_layer, head).to(device)\n",
    "        # 2. Load the saved weights\n",
    "        print(f\"Loading weights from: {CHECKPOINT_PATH}\")\n",
    "        \n",
    "        # Added weights_only=False because the file is trusted\n",
    "        # and contains more than just tensors.\n",
    "        ckpt = torch.load(CHECKPOINT_PATH, map_location=device, weights_only=False)\n",
    "        \n",
    "        model_inf.load_state_dict(ckpt[\"state_dict\"])\n",
    "        model_inf.eval()\n",
    "        print(\"Model loaded successfully.\")\n",
    "        # 3. Get class names from the checkpoint metadata\n",
    "        class_names = ckpt.get(\"meta\", {}).get(\"class_names\", [\"negative\", \"positive\"])\n",
    "        # 4. Predict the image\n",
    "        result = predict_one_with_model(TEST_IMG, model_inf, class_names=class_names)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during model loading or prediction: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361949f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "# --- Quantum Imports ---\n",
    "try:\n",
    "    import pennylane as qml\n",
    "    from pennylane import numpy as pnp\n",
    "except ImportError:\n",
    "    print(\"Warning: PennyLane not found. Quantum model functionality will fail.\")\n",
    "    qml = None\n",
    "    pnp = None\n",
    "\n",
    "# ======================================================================\n",
    "# --- 1. Common Definitions\n",
    "# ======================================================================\n",
    "\n",
    "# --- Device and Constants ---\n",
    "def device_auto() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = device_auto()\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# --- Paths ---\n",
    "CLASSICAL_MODEL_PATH = \"outputs/resnet18_finetuned_with_head.pt\"\n",
    "QUANTUM_MODEL_PATH = \"artifacts/hybrid_qml_best.pt\"\n",
    "TEST_DIR = Path(\"final_test_full\")\n",
    "\n",
    "# --- Class Lists ---\n",
    "CLASSES_CLASSICAL = ['Negative', 'Positive']\n",
    "CLASSES_QUANTUM = ['negative', 'positive'] # Note the lowercase\n",
    "\n",
    "# ======================================================================\n",
    "# --- 2. Classical Model Definitions\n",
    "# ======================================================================\n",
    "\n",
    "def load_classical_model(model_path: str, num_classes: int) -> nn.Module:\n",
    "    \"\"\"Load the trained classical model from checkpoint\"\"\"\n",
    "    model = models.resnet18(weights=None)\n",
    "    in_feats = model.fc.in_features\n",
    "    \n",
    "    if num_classes == 2:\n",
    "        model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, 1))\n",
    "    else:\n",
    "        model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, num_classes))\n",
    "    \n",
    "    try:\n",
    "        # Try loading as a full state_dict first\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint)\n",
    "    except Exception:\n",
    "        # If it fails, assume it's a dict and try to get 'state_dict'\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint.get('state_dict', checkpoint))\n",
    "        \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "classical_infer_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "def predict_classical(model: nn.Module, img_path: str, classes: List[str]) -> dict:\n",
    "    \"\"\"Predict class for a single image using the classical model\"\"\"\n",
    "    model.eval()\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = classical_infer_tfms(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        p = torch.sigmoid(logits).item()\n",
    "        pred_idx = int(p >= 0.5)\n",
    "        return {\n",
    "            \"pred_idx\": pred_idx, \n",
    "            \"pred_class\": classes[pred_idx], \n",
    "            \"prob_positive\": float(p),\n",
    "            \"prob_negative\": float(1 - p)\n",
    "        }\n",
    "\n",
    "# ======================================================================\n",
    "# --- 3. Quantum Model Definitions\n",
    "# ======================================================================\n",
    "\n",
    "if qml:\n",
    "    # Model structure constants\n",
    "    n_qubits = 4\n",
    "    n_layers = 6\n",
    "\n",
    "    # PennyLane device\n",
    "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "    class L512to4(nn.Module):\n",
    "        def __init__(self, in_dim=512, hidden_dim=4):\n",
    "            super().__init__()\n",
    "            self.fc = nn.Linear(in_dim, hidden_dim)\n",
    "            self.act = nn.Tanh()\n",
    "        def forward(self, z):\n",
    "            return self.act(self.fc(z))\n",
    "\n",
    "    def entangle_ladder():\n",
    "        qml.CNOT(wires=[1, 2])\n",
    "        qml.CNOT(wires=[0, 1])\n",
    "        qml.CNOT(wires=[2, 3])\n",
    "\n",
    "    @qml.qnode(dev, interface=\"torch\")\n",
    "    def quantum_block(x, weights):\n",
    "        for q in range(n_qubits):\n",
    "            qml.Hadamard(wires=q)\n",
    "            qml.RY(pnp.pi * x[q] / 2.0, wires=q)\n",
    "        for l in range(n_layers):\n",
    "            for q in range(n_qubits):\n",
    "                qml.RY(weights[l, q], wires=q)\n",
    "            entangle_ladder()\n",
    "        return [qml.expval(qml.PauliZ(q)) for q in range(n_qubits)]\n",
    "\n",
    "    class QuantumLayer(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            w0 = 0.01 * torch.randn(n_layers, n_qubits)\n",
    "            self.weights = nn.Parameter(w0)\n",
    "        def forward(self, x4_batch):\n",
    "            outs = []\n",
    "            for i in range(x4_batch.shape[0]):\n",
    "                y = quantum_block(x4_batch[i], self.weights)\n",
    "                y = torch.stack(y)\n",
    "                outs.append(y)\n",
    "            zq = torch.stack(outs, dim=0)\n",
    "            return zq.to(torch.float32)\n",
    "\n",
    "    class L4to2(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.fc = nn.Linear(4, 2)\n",
    "        def forward(self, z4):\n",
    "            return self.fc(z4)\n",
    "\n",
    "    class HybridModel(nn.Module):\n",
    "        def __init__(self, backbone, proj, q_layer, head):\n",
    "            super().__init__()\n",
    "            self.backbone = backbone\n",
    "            self.proj = proj\n",
    "            self.q_layer = q_layer\n",
    "            self.head = head\n",
    "        def forward(self, imgs):\n",
    "            with torch.no_grad():\n",
    "                z512 = self.backbone(imgs)\n",
    "            x4 = self.proj(z512)\n",
    "            zq = self.q_layer(x4)\n",
    "            logits = self.head(zq)\n",
    "            return logits\n",
    "\n",
    "    def load_quantum_model(model_path: str) -> nn.Module:\n",
    "        \"\"\"Build and load the hybrid quantum model\"\"\"\n",
    "        backbone = models.resnet18(weights=None)\n",
    "        backbone.fc = torch.nn.Identity()\n",
    "        proj = L512to4(in_dim=512, hidden_dim=n_qubits)\n",
    "        q_layer = QuantumLayer()\n",
    "        head = L4to2()\n",
    "        \n",
    "        model_inf = HybridModel(backbone, proj, q_layer, head).to(device)\n",
    "        \n",
    "        # Load the checkpoint (which is a dict)\n",
    "        ckpt = torch.load(model_path, map_location=device, weights_only=False)\n",
    "        model_inf.load_state_dict(ckpt[\"state_dict\"])\n",
    "        model_inf.eval()\n",
    "        \n",
    "        # Also return the class names from metadata\n",
    "        class_names = ckpt.get(\"meta\", {}).get(\"class_names\", CLASSES_QUANTUM)\n",
    "        return model_inf, class_names\n",
    "\n",
    "    quantum_infer_tfms = transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "    ])\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_quantum(model: nn.Module, img_path: str, class_names: List[str]) -> dict:\n",
    "        \"\"\"Predict class for a single image using the quantum model\"\"\"\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        x = quantum_infer_tfms(img).unsqueeze(0).to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        probs = F.softmax(logits, dim=1).squeeze(0).cpu()\n",
    "        pred_idx = int(probs.argmax().item())\n",
    "\n",
    "        return {\n",
    "            \"pred_idx\": pred_idx,\n",
    "            \"label\": class_names[pred_idx],\n",
    "            \"probs\": probs.tolist(), # [prob_neg, prob_pos]\n",
    "            \"prob_negative\": probs[0],\n",
    "            \"prob_positive\": probs[1],\n",
    "        }\n",
    "else:\n",
    "    print(\"Skipping Quantum Model definitions.\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# --- 4. Main Evaluation Function\n",
    "# ======================================================================\n",
    "\n",
    "def run_evaluation():\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # --- 1. Load Models ---\n",
    "    print(f\"Loading classical model from: {CLASSICAL_MODEL_PATH}\")\n",
    "    try:\n",
    "        classical_model = load_classical_model(CLASSICAL_MODEL_PATH, len(CLASSES_CLASSICAL))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Classical model file not found at {CLASSICAL_MODEL_PATH}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Loading quantum model from: {QUANTUM_MODEL_PATH}\")\n",
    "    try:\n",
    "        quantum_model, quantum_classes = load_quantum_model(QUANTUM_MODEL_PATH)\n",
    "        # Ensure quantum classes are lowercase for comparison\n",
    "        quantum_classes = [c.lower() for c in quantum_classes]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Quantum model file not found at {QUANTUM_MODEL_PATH}\")\n",
    "        return\n",
    "    except NameError:\n",
    "        print(\"Error: Quantum model classes are not defined. Was PennyLane imported?\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Find Test Images ---\n",
    "    print(f\"Scanning for images in: {TEST_DIR}\")\n",
    "    if not TEST_DIR.exists():\n",
    "        print(f\"Error: Test directory not found at {TEST_DIR}\")\n",
    "        return\n",
    "        \n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "    image_files = [\n",
    "        p for p in TEST_DIR.rglob('*') \n",
    "        if p.suffix.lower() in image_extensions\n",
    "    ]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"Error: No images found in {TEST_DIR}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images to test.\")\n",
    "\n",
    "    # --- 3. Run Predictions and Collect Results ---\n",
    "    all_results = []\n",
    "    print(\"Running predictions...\")\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        # Get ground truth label from parent folder name (e.g., 'positive' or 'negative')\n",
    "        gt_label = img_path.parent.name.lower()\n",
    "        \n",
    "        # Run Classical Prediction\n",
    "        c_res = predict_classical(classical_model, str(img_path), CLASSES_CLASSICAL)\n",
    "        c_pred_label = c_res['pred_class'].lower()\n",
    "        c_correct = (c_pred_label == gt_label)\n",
    "        c_prob_pos = c_res['prob_positive']\n",
    "        c_confidence = c_prob_pos if c_pred_label == 'positive' else (1 - c_prob_pos)\n",
    "        \n",
    "        # Run Quantum Prediction\n",
    "        q_res = predict_quantum(quantum_model, str(img_path), quantum_classes)\n",
    "        q_pred_label = q_res['label'].lower()\n",
    "        q_correct = (q_pred_label == gt_label)\n",
    "        q_prob_pos = q_res['prob_positive']\n",
    "        q_confidence = q_prob_pos if q_pred_label == 'positive' else (1 - q_prob_pos)\n",
    "\n",
    "        all_results.append({\n",
    "            \"path\": str(img_path.relative_to(TEST_DIR)),\n",
    "            \"gt\": gt_label,\n",
    "            \"c_pred\": c_pred_label,\n",
    "            \"c_correct\": c_correct,\n",
    "            \"c_prob_pos\": c_prob_pos,\n",
    "            \"c_confidence\": c_confidence,\n",
    "            \"q_pred\": q_pred_label,\n",
    "            \"q_correct\": q_correct,\n",
    "            \"q_prob_pos\": q_prob_pos,\n",
    "            \"q_confidence\": q_confidence,\n",
    "        })\n",
    "\n",
    "    # --- 4. Analyze and Report ---\n",
    "    total = len(all_results)\n",
    "    \n",
    "    # Overall Accuracy\n",
    "    c_total_correct = sum(1 for r in all_results if r['c_correct'])\n",
    "    q_total_correct = sum(1 for r in all_results if r['q_correct'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"  EVALUATION REPORT\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    print(f\"\\n--- 1. Overall Accuracy ---\")\n",
    "    print(f\"Classical: {c_total_correct}/{total}  ({c_total_correct/total:.2%})\")\n",
    "    print(f\"Quantum:   {q_total_correct}/{total}  ({q_total_correct/total:.2%})\")\n",
    "\n",
    "    # Probability / Confidence Analysis\n",
    "    c_conf_correct = [r['c_confidence'] for r in all_results if r['c_correct']]\n",
    "    c_conf_wrong = [r['c_confidence'] for r in all_results if not r['c_correct']]\n",
    "    q_conf_correct = [r['q_confidence'] for r in all_results if r['q_correct']]\n",
    "    q_conf_wrong = [r['q_confidence'] for r in all_results if not r['q_correct']]\n",
    "\n",
    "    print(f\"\\n--- 2. Average Confidence ---\")\n",
    "    print(f\"  (Probability assigned to the *predicted* class)\")\n",
    "    print(f\"Classical (Correct): {np.mean(c_conf_correct):.4f}\" if c_conf_correct else \"Classical (Correct): N/A\")\n",
    "    print(f\"Classical (Wrong):   {np.mean(c_conf_wrong):.4f}\" if c_conf_wrong else \"Classical (Wrong):   N/A\")\n",
    "    print(f\"Quantum (Correct):   {np.mean(q_conf_correct):.4f}\" if q_conf_correct else \"Quantum (Correct):   N/A\")\n",
    "    print(f\"Quantum (Wrong):     {np.mean(q_conf_wrong):.4f}\" if q_conf_wrong else \"Quantum (Wrong):     N/A\")\n",
    "\n",
    "    # Probability Margin Analysis (Difference from 0.5)\n",
    "    c_margins = [abs(r['c_prob_pos'] - 0.5) for r in all_results]\n",
    "    q_margins = [abs(r['q_prob_pos'] - 0.5) for r in all_results]\n",
    "\n",
    "    print(f\"\\n--- 3. Average Probability Margin ---\")\n",
    "    print(f\"  (Average distance from 0.5, a measure of decisiveness)\")\n",
    "    print(f\"Classical: {np.mean(c_margins):.4f}\")\n",
    "    print(f\"Quantum:   {np.mean(q_margins):.4f}\")\n",
    "\n",
    "    # Discrepancy Report\n",
    "    c_right_q_wrong = [r for r in all_results if r['c_correct'] and not r['q_correct']]\n",
    "    q_right_c_wrong = [r for r in all_results if not r['c_correct'] and r['q_correct']]\n",
    "    both_wrong = [r for r in all_results if not r['c_correct'] and not r['q_correct']]\n",
    "\n",
    "    print(f\"\\n--- 4. Discrepancy Report ---\")\n",
    "    \n",
    "    print(f\"\\nClassical CORRECT, Quantum WRONG ({len(c_right_q_wrong)}):\")\n",
    "    for r in c_right_q_wrong:\n",
    "        print(f\"  - {r['path']} (GT: {r['gt']})\")\n",
    "        print(f\"    Classical predicted: {r['c_pred']} ({r['c_confidence']:.3f})\")\n",
    "        print(f\"    Quantum predicted:   {r['q_pred']} ({r['q_confidence']:.3f})\")\n",
    "\n",
    "    print(f\"\\nQuantum CORRECT, Classical WRONG ({len(q_right_c_wrong)}):\")\n",
    "    for r in q_right_c_wrong:\n",
    "        print(f\"  - {r['path']} (GT: {r['gt']})\")\n",
    "        print(f\"    Classical predicted: {r['c_pred']} ({r['c_confidence']:.3f})\")\n",
    "        print(f\"    Quantum predicted:   {r['q_pred']} ({r['q_confidence']:.3f})\")\n",
    "\n",
    "    print(f\"\\nBoth WRONG ({len(both_wrong)}):\")\n",
    "    for r in both_wrong:\n",
    "        print(f\"  - {r['path']} (GT: {r['gt']})\")\n",
    "        print(f\"    Classical predicted: {r['c_pred']} ({r['c_confidence']:.3f})\")\n",
    "        print(f\"    Quantum predicted:   {r['q_pred']} ({r['q_confidence']:.3f})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"  END OF REPORT\")\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38eaaf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading classical model from: outputs/resnet18_finetuned_with_head.pt\n",
      "Loading quantum model from: artifacts/hybrid_qml_best.pt\n",
      "Scanning for images in: final_test_full\n",
      "Found 340 images to test.\n",
      "Running predictions...\n",
      "\n",
      "==============================\n",
      "  EVALUATION REPORT\n",
      "==============================\n",
      "\n",
      "--- 1. Overall Accuracy ---\n",
      "Classical: 307/340  (90.29%)\n",
      "Quantum:   315/340  (92.65%)\n",
      "\n",
      "--- 2. Average Confidence ---\n",
      "  (Probability assigned to the *predicted* class)\n",
      "Classical (Correct): 0.9787\n",
      "Classical (Wrong):   0.8966\n",
      "Quantum (Correct):   0.8082\n",
      "Quantum (Wrong):     0.7201\n",
      "\n",
      "--- 3. Average Probability Margin ---\n",
      "  (Average distance from 0.5, a measure of decisiveness)\n",
      "Classical: 0.4707\n",
      "Quantum:   0.3017\n",
      "\n",
      "--- 4. Discrepancy Report ---\n",
      "\n",
      "Classical CORRECT, Quantum WRONG (10):\n",
      "  - positive\\123 (16).jpg (GT: positive)\n",
      "    Classical predicted: positive (0.999)\n",
      "    Quantum predicted:   negative (0.604)\n",
      "  - positive\\16.jpg (GT: positive)\n",
      "    Classical predicted: positive (0.887)\n",
      "    Quantum predicted:   negative (0.793)\n",
      "  - positive\\18.jpg (GT: positive)\n",
      "    Classical predicted: positive (0.999)\n",
      "    Quantum predicted:   negative (0.572)\n",
      "  - positive\\27.jpg (GT: positive)\n",
      "    Classical predicted: positive (0.815)\n",
      "    Quantum predicted:   negative (0.740)\n",
      "  - positive\\47.jpg (GT: positive)\n",
      "    Classical predicted: positive (0.995)\n",
      "    Quantum predicted:   negative (0.676)\n",
      "  - positive\\5.jpg (GT: positive)\n",
      "    Classical predicted: positive (0.936)\n",
      "    Quantum predicted:   negative (0.706)\n",
      "  - positive\\51.jpg (GT: positive)\n",
      "    Classical predicted: positive (0.999)\n",
      "    Quantum predicted:   negative (0.550)\n",
      "  - positive\\6.jpg (GT: positive)\n",
      "    Classical predicted: positive (0.615)\n",
      "    Quantum predicted:   negative (0.559)\n",
      "  - positive\\89.jpg (GT: positive)\n",
      "    Classical predicted: positive (0.858)\n",
      "    Quantum predicted:   negative (0.767)\n",
      "  - positive\\97.jpg (GT: positive)\n",
      "    Classical predicted: positive (0.998)\n",
      "    Quantum predicted:   negative (0.743)\n",
      "\n",
      "Quantum CORRECT, Classical WRONG (18):\n",
      "  - negative\\584.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.831)\n",
      "    Quantum predicted:   negative (0.804)\n",
      "  - negative\\585.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.991)\n",
      "    Quantum predicted:   negative (0.803)\n",
      "  - negative\\586.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.996)\n",
      "    Quantum predicted:   negative (0.807)\n",
      "  - negative\\587.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.997)\n",
      "    Quantum predicted:   negative (0.803)\n",
      "  - negative\\588.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.847)\n",
      "    Quantum predicted:   negative (0.807)\n",
      "  - negative\\589.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.638)\n",
      "    Quantum predicted:   negative (0.806)\n",
      "  - negative\\70.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.507)\n",
      "    Quantum predicted:   negative (0.783)\n",
      "  - negative\\732.jpg (GT: negative)\n",
      "    Classical predicted: positive (1.000)\n",
      "    Quantum predicted:   negative (0.762)\n",
      "  - negative\\733.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.623)\n",
      "    Quantum predicted:   negative (0.799)\n",
      "  - negative\\738.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.624)\n",
      "    Quantum predicted:   negative (0.797)\n",
      "  - negative\\742.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.969)\n",
      "    Quantum predicted:   negative (0.807)\n",
      "  - negative\\753.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.979)\n",
      "    Quantum predicted:   negative (0.720)\n",
      "  - positive\\123 (17).jpg (GT: positive)\n",
      "    Classical predicted: negative (0.880)\n",
      "    Quantum predicted:   positive (0.811)\n",
      "  - positive\\21.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.876)\n",
      "    Quantum predicted:   positive (0.837)\n",
      "  - positive\\48.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.853)\n",
      "    Quantum predicted:   positive (0.643)\n",
      "  - positive\\49.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.949)\n",
      "    Quantum predicted:   positive (0.669)\n",
      "  - positive\\88.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.667)\n",
      "    Quantum predicted:   positive (0.520)\n",
      "  - positive\\96.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.712)\n",
      "    Quantum predicted:   positive (0.799)\n",
      "\n",
      "Both WRONG (15):\n",
      "  - negative\\629.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.999)\n",
      "    Quantum predicted:   positive (0.842)\n",
      "  - negative\\631.jpg (GT: negative)\n",
      "    Classical predicted: positive (0.995)\n",
      "    Quantum predicted:   positive (0.708)\n",
      "  - negative\\734.jpg (GT: negative)\n",
      "    Classical predicted: positive (1.000)\n",
      "    Quantum predicted:   positive (0.542)\n",
      "  - positive\\123 (21).jpg (GT: positive)\n",
      "    Classical predicted: negative (0.973)\n",
      "    Quantum predicted:   negative (0.805)\n",
      "  - positive\\123 (25).jpg (GT: positive)\n",
      "    Classical predicted: negative (0.998)\n",
      "    Quantum predicted:   negative (0.807)\n",
      "  - positive\\13.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.953)\n",
      "    Quantum predicted:   negative (0.795)\n",
      "  - positive\\3.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.941)\n",
      "    Quantum predicted:   negative (0.521)\n",
      "  - positive\\31.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.995)\n",
      "    Quantum predicted:   negative (0.804)\n",
      "  - positive\\52.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.992)\n",
      "    Quantum predicted:   negative (0.800)\n",
      "  - positive\\59.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.997)\n",
      "    Quantum predicted:   negative (0.780)\n",
      "  - positive\\70.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.966)\n",
      "    Quantum predicted:   negative (0.768)\n",
      "  - positive\\85.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.984)\n",
      "    Quantum predicted:   negative (0.793)\n",
      "  - positive\\91.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.982)\n",
      "    Quantum predicted:   negative (0.800)\n",
      "  - positive\\95.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.995)\n",
      "    Quantum predicted:   negative (0.730)\n",
      "  - positive\\98.jpg (GT: positive)\n",
      "    Classical predicted: negative (0.883)\n",
      "    Quantum predicted:   negative (0.798)\n",
      "\n",
      "==============================\n",
      "  END OF REPORT\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "run_evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
