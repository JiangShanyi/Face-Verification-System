{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ca002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ECE733\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Train dir: C:\\ECE733\\Final\\_bin_dataset\\train\n",
      "Val dir  : C:\\ECE733\\Final\\_bin_dataset\\val\n",
      "Noise models will be saved to: C:\\ECE733\\Final\\outputs\\noise_models\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train an ensemble of noisy Hybrid VQC models (5 experts, same T2 noise type),\n",
    "each with a different random seed, for binary face verification.\n",
    "\n",
    "Assumes:\n",
    "  - A frozen ResNet-18 backbone checkpoint exists at:\n",
    "        outputs/resnet18_backbone_only.pt\n",
    "    (or outputs/resnet18_finetuned.pt as a fallback)\n",
    "  - Training and validation images are in:\n",
    "        data/train   (subfolders: negative, positive)\n",
    "        data/val     (subfolders: negative, positive)\n",
    "\"\"\"\n",
    "\n",
    "import os, random, copy, time\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "\n",
    "# ----------------- Paths & config -----------------\n",
    "ROOT = Path(\".\")\n",
    "BACKBONE_CKPT_1 = ROOT / \"outputs\" / \"resnet18_backbone_only.pt\"\n",
    "BACKBONE_CKPT_2 = ROOT / \"outputs\" / \"resnet18_finetuned.pt\"\n",
    "\n",
    "DATA_ROOT = ROOT / \"_bin_dataset\"\n",
    "TRAIN_ROOT = DATA_ROOT / \"train\"\n",
    "VAL_ROOT   = DATA_ROOT / \"val\"\n",
    "\n",
    "NOISE_CKPT_DIR = ROOT / \"outputs\" / \"noise_models\"\n",
    "NOISE_CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 5 experts for one noise type\n",
    "N_T2_EXPERTS = 5\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Global (base) seed – we’ll offset per expert\n",
    "BASE_SEED = 123\n",
    "\n",
    "# ImageNet stats\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Data transforms\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_tfm = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "tfm = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "print(\"Train dir:\", TRAIN_ROOT.resolve())\n",
    "print(\"Val dir  :\", VAL_ROOT.resolve())\n",
    "print(\"Noise models will be saved to:\", NOISE_CKPT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cae1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded backbone from: outputs\\resnet18_backbone_only.pt\n",
      "Backbone output dim: 512\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 1. Frozen ResNet-18 backbone + 512→4 projector\n",
    "#############################################\n",
    "\n",
    "def set_global_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def load_frozen_backbone() -> Tuple[nn.Module, int]:\n",
    "    \"\"\"\n",
    "    Load the frozen ResNet-18 backbone.\n",
    "    Tries outputs/resnet18_backbone_only.pt, then outputs/resnet18_finetuned.pt.\n",
    "    \"\"\"\n",
    "    if BACKBONE_CKPT_1.exists():\n",
    "        ckpt_backbone = BACKBONE_CKPT_1\n",
    "    elif BACKBONE_CKPT_2.exists():\n",
    "        ckpt_backbone = BACKBONE_CKPT_2\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            \"Backbone weights not found.\\n\"\n",
    "            \"Expected one of:\\n\"\n",
    "            f\"  {BACKBONE_CKPT_1}\\n\"\n",
    "            f\"  {BACKBONE_CKPT_2}\"\n",
    "        )\n",
    "\n",
    "    backbone = models.resnet18(weights=None)\n",
    "    state = torch.load(ckpt_backbone, map_location=\"cpu\")\n",
    "    if isinstance(state, dict) and \"state_dict\" in state:\n",
    "        state = state[\"state_dict\"]\n",
    "    backbone.load_state_dict(state, strict=False)  # ignore fc mismatch\n",
    "\n",
    "    in_feats = backbone.fc.in_features\n",
    "    backbone.fc = nn.Identity()\n",
    "\n",
    "    backbone.to(device)\n",
    "    backbone.eval()\n",
    "    for p in backbone.parameters():\n",
    "        p.requires_grad_(False)\n",
    "\n",
    "    print(\"Loaded backbone from:\", ckpt_backbone)\n",
    "    print(\"Backbone output dim:\", in_feats)\n",
    "    return backbone, in_feats\n",
    "\n",
    "BACKBONE, BACKBONE_OUT = load_frozen_backbone()\n",
    "\n",
    "class L512to4(nn.Module):\n",
    "    \"\"\"\n",
    "    512-d CNN feature -> 4-d embedding for quantum circuit input.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=512, hidden_dim=4):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_dim, hidden_dim)\n",
    "        self.act = nn.Tanh()  # keep within [-1, 1] range\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.act(self.fc(z))  # [B, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2. Quantum circuit definition with noise\n",
    "#############################################\n",
    "\n",
    "n_qubits = 4\n",
    "n_layers = 6\n",
    "\n",
    "# Default noise strengths\n",
    "T1_gamma_default = 0.01\n",
    "T2_gamma_default = 0.02\n",
    "epsilon_default  = 0.03  # only used for rotation noise\n",
    "\n",
    "# Mixed-state device to support noisy channels\n",
    "qdev = qml.device(\"default.mixed\", wires=n_qubits)\n",
    "\n",
    "def entangle_ladder():\n",
    "    \"\"\"\n",
    "    Simple ladder entangling pattern on 4 qubits.\n",
    "    \"\"\"\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "\n",
    "@qml.qnode(qdev, interface=\"torch\")\n",
    "def quantum_block(x, weights,\n",
    "                  noise_type=\"none\",\n",
    "                  gamma_T1=0.0,\n",
    "                  gamma_T2=0.0,\n",
    "                  epsilon=0.0):\n",
    "    \"\"\"\n",
    "    x:        Tensor of shape [4] (classical embedding).\n",
    "    weights:  Tensor [n_layers, n_qubits].\n",
    "    noise_type: \"none\", \"T1\", \"T2\", \"rotation\"\n",
    "    gamma_T1: amplitude damping parameter\n",
    "    gamma_T2: dephasing parameter\n",
    "    epsilon:  over-rotation magnitude (for 'rotation' noise)\n",
    "    \"\"\"\n",
    "\n",
    "    def apply_noise():\n",
    "        # Inject noise after each layer\n",
    "        if noise_type == \"T1\":\n",
    "            for q in range(n_qubits):\n",
    "                qml.AmplitudeDamping(gamma_T1, wires=q)\n",
    "        elif noise_type == \"T2\":\n",
    "            for q in range(n_qubits):\n",
    "                qml.PhaseDamping(gamma_T2, wires=q)\n",
    "        elif noise_type == \"T12\" or noise_type == \"T12r\":\n",
    "            for q in range(n_qubits):\n",
    "                qml.AmplitudeDamping(gamma_T1, wires=q)\n",
    "                qml.PhaseDamping(gamma_T2, wires=q)\n",
    "        # rotation noise is handled in the gate angles\n",
    "\n",
    "    # ----- 1) Data encoding -----\n",
    "    for q in range(n_qubits):\n",
    "        qml.Hadamard(wires=q)\n",
    "        qml.RY(np.pi * x[q] / 2.0, wires=q)\n",
    "\n",
    "    apply_noise()\n",
    "\n",
    "    # ----- 2) Variational layers -----\n",
    "    for l in range(n_layers):\n",
    "        # Single-qubit rotations\n",
    "        for q in range(n_qubits):\n",
    "            if noise_type == \"rotation\" or noise_type == \"T12r\":\n",
    "                qml.RY(weights[l, q] + epsilon, wires=q)\n",
    "            else:\n",
    "                qml.RY(weights[l, q], wires=q)\n",
    "\n",
    "        apply_noise()\n",
    "        entangle_ladder()\n",
    "\n",
    "    # ----- 3) Measurement -----\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 3. Quantum layer, classifier head, Hybrid model\n",
    "#############################################\n",
    "\n",
    "# Helper: entanglement patterns\n",
    "def make_entangler(kind: str):\n",
    "    if kind == \"ladder\":\n",
    "        return [(1, 2), (0, 1), (2, 3)]\n",
    "    if kind == \"ring\":\n",
    "        # simple ring across 4 qubits\n",
    "        return [(0, 1), (1, 2), (2, 3), (3, 0)]\n",
    "    pairs = [(0, 1), (1, 2), (2, 3), (0, 2), (1, 3)]\n",
    "    random.shuffle(pairs)\n",
    "    return pairs[:4]\n",
    "\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational quantum layer with noise.\n",
    "\n",
    "    Compared to the original version, we now allow:\n",
    "      - variable depth (number of layers) per expert\n",
    "      - variable entanglement pattern per expert\n",
    "\n",
    "    `depth` / `pattern` can be passed explicitly, otherwise we fall back to\n",
    "    a small random choice (like in the clean ensemble notebook).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        noise_type=\"none\",\n",
    "        T1=0.0,\n",
    "        T2=0.0,\n",
    "        epsilon=0.0,\n",
    "        depth=None,\n",
    "        pairs=None,\n",
    "        pattern=None,\n",
    "        shots=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---- circuit structure (varies per expert) ----\n",
    "        self.depth = int(depth) if depth is not None else random.choice([5, 6])\n",
    "\n",
    "        if pairs is not None:\n",
    "            self.pairs = list(pairs)\n",
    "        else:\n",
    "            pat = pattern or random.choice([\"ladder\", \"ring\", \"rand\"])\n",
    "            self.pairs = make_entangler(pat)\n",
    "\n",
    "        # learnable parameters: [depth, n_qubits]\n",
    "        self.weights = nn.Parameter(0.01 * torch.randn(self.depth, n_qubits))\n",
    "\n",
    "        # ---- noise configuration ----\n",
    "        self.noise_type = noise_type\n",
    "        self.gamma_T1 = T1\n",
    "        self.gamma_T2 = T2\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # each expert gets its own mixed-state device / QNode\n",
    "        self.dev = qml.device(\"default.mixed\", wires=n_qubits, shots=shots)\n",
    "\n",
    "        def circuit(x, w):\n",
    "            # capture current config into local vars for the QNode\n",
    "            noise_type = self.noise_type\n",
    "            gamma_T1 = self.gamma_T1\n",
    "            gamma_T2 = self.gamma_T2\n",
    "            epsilon = self.epsilon\n",
    "            depth = self.depth\n",
    "            pairs = self.pairs\n",
    "\n",
    "            def apply_noise():\n",
    "                if noise_type == \"T1\":\n",
    "                    for q in range(n_qubits):\n",
    "                        qml.AmplitudeDamping(gamma_T1, wires=q)\n",
    "                elif noise_type == \"T2\":\n",
    "                    for q in range(n_qubits):\n",
    "                        qml.PhaseDamping(gamma_T2, wires=q)\n",
    "                elif noise_type == \"T12\" or noise_type == \"T12r\":\n",
    "                    for q in range(n_qubits):\n",
    "                        qml.AmplitudeDamping(gamma_T1, wires=q)\n",
    "                        qml.PhaseDamping(gamma_T2, wires=q)\n",
    "                # rotation noise is handled in the gate angles\n",
    "\n",
    "            # ----- 1) Data encoding -----\n",
    "            for q in range(n_qubits):\n",
    "                qml.Hadamard(wires=q)\n",
    "                qml.RY(np.pi * x[q] / 2.0, wires=q)\n",
    "\n",
    "            apply_noise()\n",
    "\n",
    "            # ----- 2) Variational layers -----\n",
    "            for l in range(depth):\n",
    "                # Single-qubit rotations\n",
    "                for q in range(n_qubits):\n",
    "                    if noise_type == \"rotation\" or noise_type == \"T12r\":\n",
    "                        qml.RY(w[l, q] + epsilon, wires=q)\n",
    "                    else:\n",
    "                        qml.RY(w[l, q], wires=q)\n",
    "\n",
    "                apply_noise()\n",
    "\n",
    "                # entanglement pattern chosen per expert\n",
    "                for a, b in pairs:\n",
    "                    qml.CNOT(wires=[a, b])\n",
    "\n",
    "            # ----- 3) Measurement -----\n",
    "            return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "        self.qnode = qml.QNode(circuit, self.dev, interface=\"torch\")\n",
    "\n",
    "    def forward(self, x4_batch: torch.Tensor) -> torch.Tensor:\n",
    "        outs = []\n",
    "        for i in range(x4_batch.shape[0]):\n",
    "            y = self.qnode(x4_batch[i], self.weights)\n",
    "            if not isinstance(y, torch.Tensor):\n",
    "                y = torch.stack(y)\n",
    "            outs.append(y)\n",
    "        return torch.stack(outs, dim=0).to(torch.float32)\n",
    "\n",
    "\n",
    "class L4to2(nn.Module):\n",
    "    def __init__(self, in_dim=4, hidden_dim=8, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, backbone, proj, q_layer, head):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.proj = proj\n",
    "        self.q_layer = q_layer\n",
    "        self.head = head\n",
    "\n",
    "    def forward(self, imgs: torch.Tensor) -> torch.Tensor:\n",
    "        with torch.no_grad():  # backbone frozen\n",
    "            z512 = self.backbone(imgs)  # [B, 512]\n",
    "\n",
    "        x4 = self.proj(z512)            # [B, 4]\n",
    "        zq = self.q_layer(x4)           # [B, 4]\n",
    "        logits = self.head(zq)          # [B, 2]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae189d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: ['Negative', 'Positive']\n",
      "Val classes  : ['Negative', 'Positive']\n",
      "Number of training samples: 480\n",
      "Number of validation samples: 120\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 4. Datasets and Dataloaders\n",
    "#############################################\n",
    "\n",
    "def make_dataloaders(batch_size: int = 16, num_workers: int = 0):\n",
    "    if not TRAIN_ROOT.exists():\n",
    "        raise FileNotFoundError(f\"Train dir not found: {TRAIN_ROOT}\")\n",
    "    if not VAL_ROOT.exists():\n",
    "        raise FileNotFoundError(f\"Val dir not found: {VAL_ROOT}\")\n",
    "\n",
    "    train_ds = datasets.ImageFolder(TRAIN_ROOT, transform=train_tfm)\n",
    "    val_ds   = datasets.ImageFolder(VAL_ROOT,   transform=val_tfm)\n",
    "\n",
    "    print(\"Train classes:\", train_ds.classes)\n",
    "    print(\"Val classes  :\", val_ds.classes)\n",
    "    assert train_ds.classes == val_ds.classes, \"Train and val classes must match.\"\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_ds.classes\n",
    "\n",
    "train_loader, val_loader, CLASS_NAMES = make_dataloaders(batch_size=16, num_workers=0)\n",
    "print(\"Number of training samples:\", len(train_loader.dataset))\n",
    "print(\"Number of validation samples:\", len(val_loader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17676527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 5. Generic noise-expert utilities\n",
    "#############################################\n",
    "\n",
    "T1_gamma_default = 0.02   # amplitude damping strength\n",
    "T2_gamma_default = 0.049   # dephasing strength\n",
    "epsilon_default  = 0.03   # over-rotation magnitude\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Ensemble structure configuration: depth + entanglement per expert\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Fixed small menu of structures (same for all noise types).\n",
    "# With 5 experts, each one gets a unique pattern pair.\n",
    "STRUCT_CONFIGS = [\n",
    "    {\"depth\": 6, \"pattern\": \"ladder\"},\n",
    "    {\"depth\": 6, \"pattern\": \"ring\"},\n",
    "    {\"depth\": 6, \"pattern\": \"ladder\"},\n",
    "    {\"depth\": 6, \"pattern\": \"ring\"},\n",
    "    {\"depth\": 6, \"pattern\": \"rand\"},\n",
    "]\n",
    "\n",
    "\n",
    "def get_structure_for_expert(expert_id: int):\n",
    "    cfg = STRUCT_CONFIGS[expert_id % len(STRUCT_CONFIGS)]\n",
    "    return cfg[\"depth\"], cfg[\"pattern\"]\n",
    "\n",
    "\n",
    "def make_noise_expert_model(noise_type=\"T2\", expert_id: int = 0) -> HybridModel:\n",
    "    \"\"\"\n",
    "    Build a fresh Hybrid model configured for a given noise_type and *structure*.\n",
    "\n",
    "    noise_type ∈ {\"none\", \"T1\", \"T2\", \"rotation\"}.\n",
    "    The circuit structure (depth + entanglement pattern) is chosen\n",
    "    deterministically from expert_id via get_structure_for_expert().\n",
    "    \"\"\"\n",
    "    backbone = copy.deepcopy(BACKBONE)\n",
    "    proj = L512to4(in_dim=BACKBONE_OUT, hidden_dim=4)\n",
    "\n",
    "    depth, pattern = get_structure_for_expert(expert_id)\n",
    "    common_kwargs = {\"depth\": depth, \"pattern\": pattern}\n",
    "\n",
    "    if noise_type == \"T1\":\n",
    "        q_layer = QuantumLayer(\n",
    "            noise_type=\"T1\",\n",
    "            T1=T1_gamma_default,\n",
    "            T2=0.0,\n",
    "            epsilon=0.0,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "    elif noise_type == \"T2\":\n",
    "        q_layer = QuantumLayer(\n",
    "            noise_type=\"T2\",\n",
    "            T1=0.0,\n",
    "            T2=T2_gamma_default,\n",
    "            epsilon=0.0,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "    elif noise_type == \"T12\":\n",
    "        q_layer = QuantumLayer(\n",
    "            noise_type=\"T12\",\n",
    "            T1=T1_gamma_default,\n",
    "            T2=T2_gamma_default,\n",
    "            epsilon=0.0,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "    elif noise_type == \"T12r\":\n",
    "        q_layer = QuantumLayer(\n",
    "            noise_type=\"T12r\",\n",
    "            T1=T1_gamma_default,\n",
    "            T2=T2_gamma_default,\n",
    "            epsilon=epsilon_default,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "    elif noise_type == \"rotation\":\n",
    "        q_layer = QuantumLayer(\n",
    "            noise_type=\"rotation\",\n",
    "            T1=0.0,\n",
    "            T2=0.0,\n",
    "            epsilon=epsilon_default,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "    else:  # \"none\" or anything else\n",
    "        q_layer = QuantumLayer(\n",
    "            noise_type=\"none\",\n",
    "            T1=0.0,\n",
    "            T2=0.0,\n",
    "            epsilon=0.0,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "\n",
    "    head = L4to2()\n",
    "    model = HybridModel(backbone, proj, q_layer, head).to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def accuracy_from_logits(logits: torch.Tensor, labels: torch.Tensor) -> float:\n",
    "    preds = logits.argmax(dim=1)\n",
    "    correct = (preds == labels).float().sum().item()\n",
    "    total = labels.size(0)\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "def train_one_epoch(model: nn.Module,\n",
    "                    loader: DataLoader,\n",
    "                    optimizer: torch.optim.Optimizer,\n",
    "                    criterion: nn.Module):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    total_count = 0\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_acc  += accuracy_from_logits(logits, labels) * batch_size\n",
    "        total_count += batch_size\n",
    "\n",
    "    return total_loss / total_count, total_acc / total_count\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_epoch(model: nn.Module,\n",
    "                   loader: DataLoader,\n",
    "                   criterion: nn.Module):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    total_count = 0\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Val\", leave=False):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_acc  += accuracy_from_logits(logits, labels) * batch_size\n",
    "        total_count += batch_size\n",
    "\n",
    "    return total_loss / total_count, total_acc / total_count\n",
    "\n",
    "\n",
    "def train_noise_expert(\n",
    "    expert_id: int,\n",
    "    noise_type: str,\n",
    "    ensemble_tag: str,\n",
    "    num_epochs: int = 10,\n",
    "    lr: float = 1e-3,\n",
    "    weight_decay: float = 0.0,\n",
    "    batch_size: int = 16,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Train a single noise expert for a given noise_type and ensemble_tag.\n",
    "\n",
    "    Examples:\n",
    "      noise_type=\"T1\", ensemble_tag=\"T1\"     -> hybrid_noise_T1_expert{expert_id}.pt\n",
    "      noise_type=\"rotation\", ensemble_tag=\"rot\"\n",
    "        -> hybrid_noise_rot_expert{expert_id}.pt\n",
    "      noise_type=\"T2\", ensemble_tag=\"T2\"     -> hybrid_noise_T2_expert{expert_id}.pt\n",
    "    \"\"\"\n",
    "    # Different seed per expert & noise_type to diversify training data order.\n",
    "    seed = BASE_SEED + 111 * expert_id + hash(noise_type) % 1000\n",
    "    set_global_seed(seed)\n",
    "    print(f\"\\n=== Training {noise_type} expert {expert_id} \"\n",
    "          f\"(ensemble={ensemble_tag}, seed={seed}) ===\")\n",
    "\n",
    "    # Recreate loaders so shuffling uses this seed\n",
    "    train_loader, val_loader, _ = make_dataloaders(batch_size=batch_size, num_workers=0)\n",
    "\n",
    "    # *** key change: structure (depth + entanglement) is tied to expert_id ***\n",
    "    model = make_noise_expert_model(noise_type=noise_type, expert_id=expert_id)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(model.proj.parameters()) +\n",
    "        list(model.q_layer.parameters()) +\n",
    "        list(model.head.parameters()),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    ckpt_name = f\"hybrid_noise_{ensemble_tag}_expert{expert_id}.pt\"\n",
    "    best_ckpt_path = NOISE_CKPT_DIR / ckpt_name\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"\\n[{ensemble_tag} expert {expert_id}] Epoch {epoch}/{num_epochs}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc = eval_one_epoch(model, val_loader, criterion)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"[{ensemble_tag} expert {expert_id}] \"\n",
    "              f\"Train loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
    "              f\"Val loss={val_loss:.4f}, acc={val_acc:.4f} | \"\n",
    "              f\"time={elapsed:.1f}s\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_ckpt_path)\n",
    "            print(f\"  -> New best model saved to {best_ckpt_path} (val_acc={best_val_acc:.4f})\")\n",
    "\n",
    "    print(f\"\\nFinished training {ensemble_tag} expert {expert_id}. \"\n",
    "          f\"Best val_acc={best_val_acc:.4f}\")\n",
    "    print(f\"Best checkpoint: {best_ckpt_path}\")\n",
    "    return best_ckpt_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################\n",
    "# # 6. Train the full T2-noise ensemble (5 experts)\n",
    "# #############################################\n",
    "\n",
    "# # Hyperparameters for all experts (you can tune these)\n",
    "# NUM_EPOCHS   = 6\n",
    "# LR           = 1e-3\n",
    "# WEIGHT_DECAY = 0.0\n",
    "# BATCH_SIZE   = 16\n",
    "\n",
    "# all_ckpts = []\n",
    "# for expert_id in range(N_T2_EXPERTS):\n",
    "#     ckpt_path = train_noise_expert(\n",
    "#         expert_id   = expert_id,\n",
    "#         noise_type  = \"T2\",\n",
    "#         ensemble_tag= \"T2\",\n",
    "#         num_epochs  = NUM_EPOCHS,\n",
    "#         lr          = LR,\n",
    "#         weight_decay= WEIGHT_DECAY,\n",
    "#         batch_size  = BATCH_SIZE,\n",
    "#     )\n",
    "#     all_ckpts.append(ckpt_path)\n",
    "\n",
    "# print(\"\\nAll expert checkpoints:\")\n",
    "# for p in all_ckpts:\n",
    "#     print(\"  \", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ccb3e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################\n",
    "# # 6. Train T1 and rotation ensembles (5 experts each)\n",
    "# #############################################\n",
    "\n",
    "# N_EXPERTS = 5\n",
    "# NUM_EPOCHS = 6\n",
    "# LR = 1e-3\n",
    "# WEIGHT_DECAY = 0.0\n",
    "# BATCH_SIZE = 16\n",
    "\n",
    "# # ---------- T1 ensemble ----------\n",
    "# print(\"\\n###########################\")\n",
    "# print(\"# Training T1 ensemble    #\")\n",
    "# print(\"###########################\")\n",
    "\n",
    "# #############################################\n",
    "# # Train T1-noise ensemble\n",
    "# #############################################\n",
    "# all_T1_ckpts = []\n",
    "# for expert_id in range(N_EXPERTS):\n",
    "#     ckpt_path = train_noise_expert(\n",
    "#         expert_id    = expert_id,\n",
    "#         noise_type   = \"T1\",\n",
    "#         ensemble_tag = \"T1\",   # filenames: hybrid_noise_T1_expertX.pt\n",
    "#         num_epochs   = NUM_EPOCHS,\n",
    "#         lr           = LR,\n",
    "#         weight_decay = WEIGHT_DECAY,\n",
    "#         batch_size   = BATCH_SIZE,\n",
    "#     )\n",
    "#     all_T1_ckpts.append(ckpt_path)\n",
    "\n",
    "\n",
    "\n",
    "# # ---------- rotation ensemble ----------\n",
    "# print(\"\\n###########################\")\n",
    "# print(\"# Training rotation ensemble\")\n",
    "# print(\"###########################\")\n",
    "\n",
    "# #############################################\n",
    "# # Train rotation-noise ensemble\n",
    "# #############################################\n",
    "# all_rot_ckpts = []\n",
    "# for expert_id in range(N_EXPERTS):\n",
    "#     ckpt_path = train_noise_expert(\n",
    "#         expert_id    = expert_id,\n",
    "#         noise_type   = \"rotation\",\n",
    "#         ensemble_tag = \"rot\",   # filenames: hybrid_noise_rot_expertX.pt\n",
    "#         num_epochs   = NUM_EPOCHS,\n",
    "#         lr           = LR,\n",
    "#         weight_decay = WEIGHT_DECAY,\n",
    "#         batch_size   = BATCH_SIZE,\n",
    "#     )\n",
    "#     all_rot_ckpts.append(ckpt_path)\n",
    "\n",
    "\n",
    "# print(\"\\nRotation expert checkpoints:\")\n",
    "# for p in all_rot_ckpts:\n",
    "#     print(\"  \", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91725c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training T12 expert 0 (ensemble=T12, seed=186) ===\n",
      "Train classes: ['Negative', 'Positive']\n",
      "Val classes  : ['Negative', 'Positive']\n",
      "\n",
      "[T12 expert 0] Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 0] Train loss=0.6359, acc=0.5000 | Val loss=0.5888, acc=0.5000 | time=110.2s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12_expert0.pt (val_acc=0.5000)\n",
      "\n",
      "[T12 expert 0] Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 0] Train loss=0.5500, acc=0.5000 | Val loss=0.5066, acc=0.5000 | time=108.3s\n",
      "\n",
      "[T12 expert 0] Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 0] Train loss=0.4720, acc=0.7104 | Val loss=0.4230, acc=0.9667 | time=104.7s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12_expert0.pt (val_acc=0.9667)\n",
      "\n",
      "[T12 expert 0] Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 0] Train loss=0.3790, acc=0.9833 | Val loss=0.3415, acc=0.9750 | time=108.4s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12_expert0.pt (val_acc=0.9750)\n",
      "\n",
      "[T12 expert 0] Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 0] Train loss=0.3318, acc=0.9542 | Val loss=0.2938, acc=0.9583 | time=110.2s\n",
      "\n",
      "[T12 expert 0] Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 0] Train loss=0.2529, acc=0.9729 | Val loss=0.2279, acc=0.9750 | time=111.3s\n",
      "\n",
      "Finished training T12 expert 0. Best val_acc=0.9750\n",
      "Best checkpoint: outputs\\noise_models\\hybrid_noise_T12_expert0.pt\n",
      "\n",
      "=== Training T12 expert 1 (ensemble=T12, seed=297) ===\n",
      "Train classes: ['Negative', 'Positive']\n",
      "Val classes  : ['Negative', 'Positive']\n",
      "\n",
      "[T12 expert 1] Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 1] Train loss=0.6913, acc=0.5000 | Val loss=0.6714, acc=0.5000 | time=116.4s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12_expert1.pt (val_acc=0.5000)\n",
      "\n",
      "[T12 expert 1] Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 1] Train loss=0.6549, acc=0.5000 | Val loss=0.6353, acc=0.5000 | time=116.1s\n",
      "\n",
      "[T12 expert 1] Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 1] Train loss=0.6192, acc=0.5000 | Val loss=0.5962, acc=0.5000 | time=117.6s\n",
      "\n",
      "[T12 expert 1] Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 1] Train loss=0.5740, acc=0.8792 | Val loss=0.5498, acc=0.9750 | time=119.4s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12_expert1.pt (val_acc=0.9750)\n",
      "\n",
      "[T12 expert 1] Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 1] Train loss=0.5308, acc=0.9708 | Val loss=0.5076, acc=0.9750 | time=120.7s\n",
      "\n",
      "[T12 expert 1] Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 1] Train loss=0.4649, acc=0.9708 | Val loss=0.4189, acc=0.9750 | time=123.4s\n",
      "\n",
      "Finished training T12 expert 1. Best val_acc=0.9750\n",
      "Best checkpoint: outputs\\noise_models\\hybrid_noise_T12_expert1.pt\n",
      "\n",
      "=== Training T12 expert 2 (ensemble=T12, seed=408) ===\n",
      "Train classes: ['Negative', 'Positive']\n",
      "Val classes  : ['Negative', 'Positive']\n",
      "\n",
      "[T12 expert 2] Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 2] Train loss=0.5503, acc=0.7271 | Val loss=0.4691, acc=0.9583 | time=113.0s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12_expert2.pt (val_acc=0.9583)\n",
      "\n",
      "[T12 expert 2] Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 2] Train loss=0.4190, acc=0.9729 | Val loss=0.3705, acc=0.9750 | time=109.6s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12_expert2.pt (val_acc=0.9750)\n",
      "\n",
      "[T12 expert 2] Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 2] Train loss=0.3285, acc=0.9729 | Val loss=0.2930, acc=0.9667 | time=117.2s\n",
      "\n",
      "[T12 expert 2] Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 2] Train loss=0.2515, acc=0.9812 | Val loss=0.2247, acc=0.9667 | time=109.4s\n",
      "\n",
      "[T12 expert 2] Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 2] Train loss=0.1880, acc=0.9812 | Val loss=0.1832, acc=0.9750 | time=114.1s\n",
      "\n",
      "[T12 expert 2] Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 2] Train loss=0.1620, acc=0.9771 | Val loss=0.1577, acc=0.9750 | time=117.2s\n",
      "\n",
      "Finished training T12 expert 2. Best val_acc=0.9750\n",
      "Best checkpoint: outputs\\noise_models\\hybrid_noise_T12_expert2.pt\n",
      "\n",
      "=== Training T12 expert 3 (ensemble=T12, seed=519) ===\n",
      "Train classes: ['Negative', 'Positive']\n",
      "Val classes  : ['Negative', 'Positive']\n",
      "\n",
      "[T12 expert 3] Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 3] Train loss=0.6233, acc=0.5000 | Val loss=0.5723, acc=0.9083 | time=118.6s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12_expert3.pt (val_acc=0.9083)\n",
      "\n",
      "[T12 expert 3] Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 3] Train loss=0.5292, acc=0.9583 | Val loss=0.4859, acc=0.9750 | time=117.8s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12_expert3.pt (val_acc=0.9750)\n",
      "\n",
      "[T12 expert 3] Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 3] Train loss=0.4397, acc=0.9812 | Val loss=0.3988, acc=0.9750 | time=117.7s\n",
      "\n",
      "[T12 expert 3] Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 3] Train loss=0.3584, acc=0.9792 | Val loss=0.3273, acc=0.9750 | time=119.1s\n",
      "\n",
      "[T12 expert 3] Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 3] Train loss=0.2921, acc=0.9750 | Val loss=0.2565, acc=0.9750 | time=125.7s\n",
      "\n",
      "[T12 expert 3] Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 3] Train loss=0.2179, acc=0.9896 | Val loss=0.2061, acc=0.9833 | time=122.9s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12_expert3.pt (val_acc=0.9833)\n",
      "\n",
      "Finished training T12 expert 3. Best val_acc=0.9833\n",
      "Best checkpoint: outputs\\noise_models\\hybrid_noise_T12_expert3.pt\n",
      "\n",
      "=== Training T12 expert 4 (ensemble=T12, seed=630) ===\n",
      "Train classes: ['Negative', 'Positive']\n",
      "Val classes  : ['Negative', 'Positive']\n",
      "\n",
      "[T12 expert 4] Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 4] Train loss=0.6234, acc=0.5000 | Val loss=0.5904, acc=0.5000 | time=114.3s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12_expert4.pt (val_acc=0.5000)\n",
      "\n",
      "[T12 expert 4] Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 4] Train loss=0.5704, acc=0.5000 | Val loss=0.5504, acc=0.5000 | time=122.6s\n",
      "\n",
      "[T12 expert 4] Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 4] Train loss=0.5312, acc=0.5000 | Val loss=0.5132, acc=0.5000 | time=119.4s\n",
      "\n",
      "[T12 expert 4] Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 4] Train loss=0.4948, acc=0.5000 | Val loss=0.4801, acc=0.5000 | time=120.5s\n",
      "\n",
      "[T12 expert 4] Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 4] Train loss=0.4605, acc=0.5000 | Val loss=0.4502, acc=0.5000 | time=117.6s\n",
      "\n",
      "[T12 expert 4] Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12 expert 4] Train loss=0.4362, acc=0.5000 | Val loss=0.4281, acc=0.5000 | time=116.1s\n",
      "\n",
      "Finished training T12 expert 4. Best val_acc=0.5000\n",
      "Best checkpoint: outputs\\noise_models\\hybrid_noise_T12_expert4.pt\n",
      "\n",
      "All expert checkpoints:\n",
      "   outputs\\noise_models\\hybrid_noise_T12_expert0.pt\n",
      "   outputs\\noise_models\\hybrid_noise_T12_expert1.pt\n",
      "   outputs\\noise_models\\hybrid_noise_T12_expert2.pt\n",
      "   outputs\\noise_models\\hybrid_noise_T12_expert3.pt\n",
      "   outputs\\noise_models\\hybrid_noise_T12_expert4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 6. Train the full T12-noise ensemble (5 experts)\n",
    "#############################################\n",
    "\n",
    "# Hyperparameters for all experts (you can tune these)\n",
    "NUM_EPOCHS   = 6\n",
    "LR           = 1e-3\n",
    "WEIGHT_DECAY = 0.0\n",
    "BATCH_SIZE   = 16\n",
    "\n",
    "all_ckpts = []\n",
    "for expert_id in range(N_T2_EXPERTS):\n",
    "    ckpt_path = train_noise_expert(\n",
    "        expert_id   = expert_id,\n",
    "        noise_type  = \"T12\",\n",
    "        ensemble_tag= \"T12\",\n",
    "        num_epochs  = NUM_EPOCHS,\n",
    "        lr          = LR,\n",
    "        weight_decay= WEIGHT_DECAY,\n",
    "        batch_size  = BATCH_SIZE,\n",
    "    )\n",
    "    all_ckpts.append(ckpt_path)\n",
    "\n",
    "print(\"\\nAll expert checkpoints:\")\n",
    "for p in all_ckpts:\n",
    "    print(\"  \", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9babd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training T12r expert 0 (ensemble=T12r, seed=196) ===\n",
      "Train classes: ['Negative', 'Positive']\n",
      "Val classes  : ['Negative', 'Positive']\n",
      "\n",
      "[T12r expert 0] Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 0] Train loss=0.5895, acc=0.9167 | Val loss=0.5357, acc=0.9750 | time=105.3s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12r_expert0.pt (val_acc=0.9750)\n",
      "\n",
      "[T12r expert 0] Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 0] Train loss=0.4734, acc=0.9792 | Val loss=0.4183, acc=0.9750 | time=103.3s\n",
      "\n",
      "[T12r expert 0] Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 0] Train loss=0.3802, acc=0.9688 | Val loss=0.3304, acc=0.9750 | time=113.4s\n",
      "\n",
      "[T12r expert 0] Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 0] Train loss=0.2864, acc=0.9875 | Val loss=0.2577, acc=0.9750 | time=104.8s\n",
      "\n",
      "[T12r expert 0] Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 0] Train loss=0.2139, acc=0.9875 | Val loss=0.2018, acc=0.9750 | time=108.3s\n",
      "\n",
      "[T12r expert 0] Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 0] Train loss=0.1859, acc=0.9771 | Val loss=0.1588, acc=0.9833 | time=123.0s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12r_expert0.pt (val_acc=0.9833)\n",
      "\n",
      "Finished training T12r expert 0. Best val_acc=0.9833\n",
      "Best checkpoint: outputs\\noise_models\\hybrid_noise_T12r_expert0.pt\n",
      "\n",
      "=== Training T12r expert 1 (ensemble=T12r, seed=307) ===\n",
      "Train classes: ['Negative', 'Positive']\n",
      "Val classes  : ['Negative', 'Positive']\n",
      "\n",
      "[T12r expert 1] Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 1] Train loss=0.5937, acc=0.7958 | Val loss=0.5360, acc=0.9750 | time=114.9s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12r_expert1.pt (val_acc=0.9750)\n",
      "\n",
      "[T12r expert 1] Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 1] Train loss=0.4948, acc=0.9812 | Val loss=0.4505, acc=0.9750 | time=121.3s\n",
      "\n",
      "[T12r expert 1] Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 1] Train loss=0.4093, acc=0.9792 | Val loss=0.3747, acc=0.9750 | time=132.8s\n",
      "\n",
      "[T12r expert 1] Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 1] Train loss=0.3419, acc=0.9750 | Val loss=0.3032, acc=0.9750 | time=122.3s\n",
      "\n",
      "[T12r expert 1] Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 1] Train loss=0.2673, acc=0.9812 | Val loss=0.2446, acc=0.9750 | time=124.5s\n",
      "\n",
      "[T12r expert 1] Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 1] Train loss=0.2224, acc=0.9750 | Val loss=0.2074, acc=0.9750 | time=122.0s\n",
      "\n",
      "Finished training T12r expert 1. Best val_acc=0.9750\n",
      "Best checkpoint: outputs\\noise_models\\hybrid_noise_T12r_expert1.pt\n",
      "\n",
      "=== Training T12r expert 2 (ensemble=T12r, seed=418) ===\n",
      "Train classes: ['Negative', 'Positive']\n",
      "Val classes  : ['Negative', 'Positive']\n",
      "\n",
      "[T12r expert 2] Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 2] Train loss=0.5006, acc=0.9229 | Val loss=0.4428, acc=0.9583 | time=114.0s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12r_expert2.pt (val_acc=0.9583)\n",
      "\n",
      "[T12r expert 2] Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 2] Train loss=0.4034, acc=0.9792 | Val loss=0.3644, acc=0.9750 | time=116.5s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12r_expert2.pt (val_acc=0.9750)\n",
      "\n",
      "[T12r expert 2] Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 2] Train loss=0.3316, acc=0.9771 | Val loss=0.2917, acc=0.9750 | time=113.9s\n",
      "\n",
      "[T12r expert 2] Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 2] Train loss=0.2630, acc=0.9792 | Val loss=0.2383, acc=0.9750 | time=115.3s\n",
      "\n",
      "[T12r expert 2] Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 2] Train loss=0.2163, acc=0.9729 | Val loss=0.1922, acc=0.9750 | time=109.9s\n",
      "\n",
      "[T12r expert 2] Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 2] Train loss=0.1766, acc=0.9812 | Val loss=0.1644, acc=0.9750 | time=114.2s\n",
      "\n",
      "Finished training T12r expert 2. Best val_acc=0.9750\n",
      "Best checkpoint: outputs\\noise_models\\hybrid_noise_T12r_expert2.pt\n",
      "\n",
      "=== Training T12r expert 3 (ensemble=T12r, seed=529) ===\n",
      "Train classes: ['Negative', 'Positive']\n",
      "Val classes  : ['Negative', 'Positive']\n",
      "\n",
      "[T12r expert 3] Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 3] Train loss=0.5208, acc=0.9354 | Val loss=0.4566, acc=0.9750 | time=118.5s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12r_expert3.pt (val_acc=0.9750)\n",
      "\n",
      "[T12r expert 3] Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 3] Train loss=0.4166, acc=0.9833 | Val loss=0.3758, acc=0.9750 | time=135.5s\n",
      "\n",
      "[T12r expert 3] Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 3] Train loss=0.3414, acc=0.9833 | Val loss=0.3028, acc=0.9750 | time=125.2s\n",
      "\n",
      "[T12r expert 3] Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 3] Train loss=0.2842, acc=0.9708 | Val loss=0.2550, acc=0.9750 | time=123.2s\n",
      "\n",
      "[T12r expert 3] Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 3] Train loss=0.2271, acc=0.9854 | Val loss=0.2184, acc=0.9667 | time=131.2s\n",
      "\n",
      "[T12r expert 3] Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 3] Train loss=0.1835, acc=0.9812 | Val loss=0.1767, acc=0.9750 | time=117.9s\n",
      "\n",
      "Finished training T12r expert 3. Best val_acc=0.9750\n",
      "Best checkpoint: outputs\\noise_models\\hybrid_noise_T12r_expert3.pt\n",
      "\n",
      "=== Training T12r expert 4 (ensemble=T12r, seed=640) ===\n",
      "Train classes: ['Negative', 'Positive']\n",
      "Val classes  : ['Negative', 'Positive']\n",
      "\n",
      "[T12r expert 4] Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 4] Train loss=0.5705, acc=0.9229 | Val loss=0.5194, acc=0.9583 | time=123.9s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12r_expert4.pt (val_acc=0.9583)\n",
      "\n",
      "[T12r expert 4] Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 4] Train loss=0.4803, acc=0.9771 | Val loss=0.4464, acc=0.9750 | time=121.2s\n",
      "  -> New best model saved to outputs\\noise_models\\hybrid_noise_T12r_expert4.pt (val_acc=0.9750)\n",
      "\n",
      "[T12r expert 4] Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 4] Train loss=0.4069, acc=0.9812 | Val loss=0.3739, acc=0.9750 | time=124.0s\n",
      "\n",
      "[T12r expert 4] Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 4] Train loss=0.3302, acc=0.9771 | Val loss=0.2915, acc=0.9750 | time=120.1s\n",
      "\n",
      "[T12r expert 4] Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 4] Train loss=0.2685, acc=0.9771 | Val loss=0.2500, acc=0.9750 | time=123.5s\n",
      "\n",
      "[T12r expert 4] Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T12r expert 4] Train loss=0.2086, acc=0.9875 | Val loss=0.1965, acc=0.9750 | time=118.5s\n",
      "\n",
      "Finished training T12r expert 4. Best val_acc=0.9750\n",
      "Best checkpoint: outputs\\noise_models\\hybrid_noise_T12r_expert4.pt\n",
      "\n",
      "All expert checkpoints:\n",
      "   outputs\\noise_models\\hybrid_noise_T12r_expert0.pt\n",
      "   outputs\\noise_models\\hybrid_noise_T12r_expert1.pt\n",
      "   outputs\\noise_models\\hybrid_noise_T12r_expert2.pt\n",
      "   outputs\\noise_models\\hybrid_noise_T12r_expert3.pt\n",
      "   outputs\\noise_models\\hybrid_noise_T12r_expert4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 6. Train the full T2-noise ensemble (5 experts)\n",
    "#############################################\n",
    "\n",
    "# Hyperparameters for all experts (you can tune these)\n",
    "NUM_EPOCHS   = 6\n",
    "LR           = 1e-3\n",
    "WEIGHT_DECAY = 0.0\n",
    "BATCH_SIZE   = 16\n",
    "\n",
    "all_ckpts = []\n",
    "for expert_id in range(N_T2_EXPERTS):\n",
    "    ckpt_path = train_noise_expert(\n",
    "        expert_id   = expert_id,\n",
    "        noise_type  = \"T12r\",\n",
    "        ensemble_tag= \"T12r\",\n",
    "        num_epochs  = NUM_EPOCHS,\n",
    "        lr          = LR,\n",
    "        weight_decay= WEIGHT_DECAY,\n",
    "        batch_size  = BATCH_SIZE,\n",
    "    )\n",
    "    all_ckpts.append(ckpt_path)\n",
    "\n",
    "print(\"\\nAll expert checkpoints:\")\n",
    "for p in all_ckpts:\n",
    "    print(\"  \", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f9d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hybrid_noise_T12_expert0.pt (expert_id=0, noise_type=T12)\n",
      "Loading hybrid_noise_T12_expert1.pt (expert_id=1, noise_type=T12)\n",
      "Loading hybrid_noise_T12_expert2.pt (expert_id=2, noise_type=T12)\n",
      "Loading hybrid_noise_T12_expert3.pt (expert_id=3, noise_type=T12)\n",
      "Loading hybrid_noise_T12_expert4.pt (expert_id=4, noise_type=T12)\n",
      "Loaded 5 experts for noise_tag='T12'.\n",
      "Loading hybrid_noise_T12r_expert0.pt (expert_id=0, noise_type=T12r)\n",
      "Loading hybrid_noise_T12r_expert1.pt (expert_id=1, noise_type=T12r)\n",
      "Loading hybrid_noise_T12r_expert2.pt (expert_id=2, noise_type=T12r)\n",
      "Loading hybrid_noise_T12r_expert3.pt (expert_id=3, noise_type=T12r)\n",
      "Loading hybrid_noise_T12r_expert4.pt (expert_id=4, noise_type=T12r)\n",
      "Loaded 5 experts for noise_tag='T12r'.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "CKPT_DIR = Path(\"outputs/noise_models\")\n",
    "FINAL_ROOT = Path(\"final_test_full\")\n",
    "\n",
    "# Noise hyperparams\n",
    "T1_gamma_default = 0.01\n",
    "T2_gamma_default = 0.02\n",
    "epsilon_default  = 0.03\n",
    "\n",
    "# ================================================================\n",
    "# Inference helpers: build experts with the same structure as train\n",
    "# ================================================================\n",
    "\n",
    "def make_noise_expert_model_for_inference(noise_type: str, expert_id: int):\n",
    "    \"\"\"\n",
    "    Build a HybridModel with the right noise configuration *and*\n",
    "    the same (depth, entanglement pattern) that was used at training\n",
    "    time for this expert_id.\n",
    "    \"\"\"\n",
    "    # backbone is already frozen globally; use a copy per expert\n",
    "    backbone = copy.deepcopy(BACKBONE)\n",
    "    proj = L512to4(in_dim=BACKBONE_OUT, hidden_dim=4)\n",
    "\n",
    "    depth, pattern = get_structure_for_expert(expert_id)\n",
    "    common_kwargs = {\"depth\": depth, \"pattern\": pattern}\n",
    "\n",
    "    if noise_type == \"T1\":\n",
    "        q_layer = QuantumLayer(\n",
    "            noise_type=\"T1\",\n",
    "            T1=T1_gamma_default,\n",
    "            T2=0.0,\n",
    "            epsilon=0.0,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "    elif noise_type == \"T2\":\n",
    "        q_layer = QuantumLayer(\n",
    "            noise_type=\"T2\",\n",
    "            T1=0.0,\n",
    "            T2=T2_gamma_default,\n",
    "            epsilon=0.0,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "    elif noise_type == \"T12\":\n",
    "        q_layer = QuantumLayer(\n",
    "            noise_type=\"T12\",\n",
    "            T1=T1_gamma_default,\n",
    "            T2=T2_gamma_default,\n",
    "            epsilon=0.0,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "    elif noise_type == \"T12r\":\n",
    "        q_layer = QuantumLayer(\n",
    "            noise_type=\"T12r\",\n",
    "            T1=T1_gamma_default,\n",
    "            T2=T2_gamma_default,\n",
    "            epsilon=epsilon_default,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "    elif noise_type == \"rotation\":\n",
    "        q_layer = QuantumLayer(\n",
    "            noise_type=\"rotation\",\n",
    "            T1=0.0,\n",
    "            T2=0.0,\n",
    "            epsilon=epsilon_default,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "    else:\n",
    "        q_layer = QuantumLayer(\n",
    "            noise_type=\"none\",\n",
    "            T1=0.0,\n",
    "            T2=0.0,\n",
    "            epsilon=0.0,\n",
    "            **common_kwargs,\n",
    "        )\n",
    "\n",
    "    head = L4to2()\n",
    "    model = HybridModel(backbone, proj, q_layer, head).to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_noise_ensemble(noise_tag: str, noise_type: str):\n",
    "    \"\"\"\n",
    "    noise_tag controls filename pattern:\n",
    "      - 'T2'  -> hybrid_noise_T2_expert*.pt\n",
    "      - 'T1'  -> hybrid_noise_T1_expert*.pt\n",
    "      - 'rot' -> hybrid_noise_rot_expert*.pt\n",
    "    noise_type is the semantic noise type (\"T1\", \"T2\", \"rotation\").\n",
    "\n",
    "    We now parse expert_id from the filename so that we can recreate\n",
    "    the correct circuit structure for each expert.\n",
    "    \"\"\"\n",
    "    pattern = f\"hybrid_noise_{noise_tag}_expert*.pt\"\n",
    "    models = []\n",
    "\n",
    "    for ckpt_path in sorted(CKPT_DIR.glob(pattern)):\n",
    "        name = ckpt_path.stem\n",
    "        try:\n",
    "            expert_id = int(name.split(\"expert\")[-1])\n",
    "        except ValueError:\n",
    "            print(f\"Warning: could not parse expert id from {name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Loading {ckpt_path.name} (expert_id={expert_id}, noise_type={noise_type})\")\n",
    "        m = make_noise_expert_model_for_inference(noise_type=noise_type,\n",
    "                                                  expert_id=expert_id)\n",
    "\n",
    "        obj = torch.load(ckpt_path, map_location=device)\n",
    "        # support both plain state_dict and {\"model_state\": ...}\n",
    "        if isinstance(obj, dict) and \"model_state\" in obj:\n",
    "            state = obj[\"model_state\"]\n",
    "        else:\n",
    "            state = obj\n",
    "\n",
    "        m.load_state_dict(state, strict=False)\n",
    "        m.eval()\n",
    "        models.append(m)\n",
    "\n",
    "    print(f\"Loaded {len(models)} experts for noise_tag='{noise_tag}'.\")\n",
    "    return models\n",
    "\n",
    "\n",
    "# Actually load your ensembles (whatever you trained)\n",
    "# ensemble_T2  = load_noise_ensemble(\"T2\",  \"T2\")\n",
    "# ensemble_T1  = load_noise_ensemble(\"T1\",  \"T1\")\n",
    "# ensemble_rot = load_noise_ensemble(\"rot\", \"rotation\")\n",
    "ensemble_T12  = load_noise_ensemble(\"T12\",  \"T12\")\n",
    "ensemble_T12r  = load_noise_ensemble(\"T12r\",  \"T12r\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9436514",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_ensemble_on_final_test(models_list, name: str = \"\"):\n",
    "    if not FINAL_ROOT.exists():\n",
    "        raise FileNotFoundError(f\"final_test directory not found at: {FINAL_ROOT}\")\n",
    "\n",
    "    if len(models_list) == 0:\n",
    "        print(f\"[{name}] No models in ensemble, skipping.\")\n",
    "        return None\n",
    "\n",
    "    ds = datasets.ImageFolder(FINAL_ROOT, transform=tfm)\n",
    "    loader = DataLoader(ds, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "    class_names = ds.classes\n",
    "    print(f\"\\n=== Evaluating ensemble '{name}' on final_test ===\")\n",
    "    print(\"Classes:\", class_names)\n",
    "    print(\"Num images:\", len(ds))\n",
    "    print(\"Num experts in ensemble:\", len(models_list))\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds_ens = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=f\"final_test [{name}]\"):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Per-expert logits\n",
    "            logits_list = [m(imgs) for m in models_list]  # list of [B,2]\n",
    "\n",
    "            # Stack to [E,B,2] then average softmax probabilities\n",
    "            stacked = torch.stack(logits_list, dim=0)      # [E,B,2]\n",
    "            probs   = F.softmax(stacked, dim=2)            # [E,B,2]\n",
    "            avg_probs = probs.mean(dim=0)                  # [B,2]\n",
    "            ens_preds_batch = avg_probs.argmax(dim=1).cpu()\n",
    "\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds_ens.append(ens_preds_batch)\n",
    "\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    all_preds_ens = torch.cat(all_preds_ens).numpy()\n",
    "\n",
    "    acc = float((all_preds_ens == all_labels).mean())\n",
    "    acc_percent = acc * 100.0\n",
    "\n",
    "    print(f\"\\n[{name}] Overall accuracy on final_test: {acc_percent:.2f}%\")\n",
    "\n",
    "    print(\"\\nPer-class accuracy:\")\n",
    "    for idx, cname in enumerate(class_names):\n",
    "        mask = (all_labels == idx)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        cls_acc = float((all_preds_ens[mask] == all_labels[mask]).mean()) * 100.0\n",
    "        print(f\"  Class '{cname}': {cls_acc:.2f}% (n={mask.sum()})\")\n",
    "\n",
    "    return acc_percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dfe4c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating ensemble 'T12' on final_test ===\n",
      "Classes: ['negative', 'positive']\n",
      "Num images: 340\n",
      "Num experts in ensemble: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "final_test [T12]: 100%|██████████| 6/6 [03:35<00:00, 36.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[T12] Overall accuracy on final_test: 92.94%\n",
      "\n",
      "Per-class accuracy:\n",
      "  Class 'negative': 98.18% (n=220)\n",
      "  Class 'positive': 83.33% (n=120)\n",
      "\n",
      "=== Evaluating ensemble 'T12r' on final_test ===\n",
      "Classes: ['negative', 'positive']\n",
      "Num images: 340\n",
      "Num experts in ensemble: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "final_test [T12r]: 100%|██████████| 6/6 [03:49<00:00, 38.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[T12r] Overall accuracy on final_test: 93.24%\n",
      "\n",
      "Per-class accuracy:\n",
      "  Class 'negative': 98.64% (n=220)\n",
      "  Class 'positive': 83.33% (n=120)\n",
      "\n",
      "\n",
      "Summary of final accuracies (percent):\n",
      "  T12: 92.94%\n",
      "  T12r: 93.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# if len(ensemble_T2) > 0:\n",
    "#     results[\"T2\"] = evaluate_ensemble_on_final_test(ensemble_T2, name=\"T2\")\n",
    "\n",
    "# if len(ensemble_T1) > 0:\n",
    "#     results[\"T1\"] = evaluate_ensemble_on_final_test(ensemble_T1, name=\"T1\")\n",
    "\n",
    "# if len(ensemble_rot) > 0:\n",
    "#     results[\"rot\"] = evaluate_ensemble_on_final_test(ensemble_rot, name=\"rotation\")\n",
    "\n",
    "if len(ensemble_T12) > 0:\n",
    "    results[\"T12\"] = evaluate_ensemble_on_final_test(ensemble_T12, name=\"T12\")\n",
    "\n",
    "if len(ensemble_T12r) > 0:\n",
    "    results[\"T12r\"] = evaluate_ensemble_on_final_test(ensemble_T12r, name=\"T12r\")\n",
    "\n",
    "print(\"\\n\\nSummary of final accuracies (percent):\")\n",
    "for k, v in results.items():\n",
    "    print(f\"  {k}: {v:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
