{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360e4adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Imports & basic config ---\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "def device_auto() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = device_auto()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ab9b7",
   "metadata": {},
   "source": [
    "Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataloaders for aligned 224x224 crops (ImageFolder layout) ---\n",
    "\n",
    "def make_dataloaders(\n",
    "    train_dir: str,\n",
    "    val_dir: str,\n",
    "    batch_size: int = 64,\n",
    "    num_workers: int = 4,\n",
    "    aug: bool = True,\n",
    ") -> Tuple[DataLoader, DataLoader, List[str]]:\n",
    "    # Only light aug; no Resize/CenterCrop because files are already 224x224\n",
    "    if aug:\n",
    "        train_tfms = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "        ])\n",
    "    else:\n",
    "        train_tfms = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "        ])\n",
    "\n",
    "    val_tfms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "    ])\n",
    "\n",
    "    train_ds = datasets.ImageFolder(train_dir, transform=train_tfms)\n",
    "    val_ds   = datasets.ImageFolder(val_dir,   transform=val_tfms)\n",
    "\n",
    "    classes = train_ds.classes\n",
    "    assert classes == val_ds.classes, \"Train/val classes differ!\"\n",
    "\n",
    "    pin_memory = torch.cuda.is_available()\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, pin_memory=pin_memory)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=num_workers, pin_memory=pin_memory)\n",
    "    return train_loader, val_loader, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824bca29",
   "metadata": {},
   "source": [
    "Build model & utilities (freeze FC, save backbone-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93d776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build ResNet18 with a replaceable head + helpers ---\n",
    "\n",
    "def build_resnet18(num_classes: int) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Loads ImageNet-pretrained ResNet-18 and replaces the final head:\n",
    "    - Binary (2 classes) -> 1 logit (for BCEWithLogitsLoss)\n",
    "    - Multi-class (K>=3) -> K logits (for CrossEntropyLoss)\n",
    "    \"\"\"\n",
    "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    in_feats = model.fc.in_features\n",
    "    if num_classes == 2:\n",
    "        model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, 1))\n",
    "    else:\n",
    "        model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, num_classes))\n",
    "    return model\n",
    "\n",
    "def freeze_fc_only(model: nn.Module):\n",
    "    \"\"\"Freeze only the classifier head so backbone trains.\"\"\"\n",
    "    for p in model.fc.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "def save_backbone_only(model: nn.Module, path: str, img_size: int = 224):\n",
    "    \"\"\"\n",
    "    Save a checkpoint containing only the backbone (drops fc.* keys).\n",
    "    This avoids head-shape mismatch later.\n",
    "    \"\"\"\n",
    "    state = model.state_dict()\n",
    "    backbone_only = {k: v for k, v in state.items() if not k.startswith(\"fc.\")}\n",
    "    torch.save({\n",
    "        \"arch\": \"resnet18\",\n",
    "        \"state_dict\": backbone_only,\n",
    "        \"img_size\": img_size,\n",
    "        \"mean\": IMAGENET_MEAN,\n",
    "        \"std\":  IMAGENET_STD,\n",
    "    }, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305658cc",
   "metadata": {},
   "source": [
    "Eval helper (loss + accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "270bc40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation (loss + accuracy) ---\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device, num_classes: int) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss() if num_classes == 2 else nn.CrossEntropyLoss()\n",
    "\n",
    "    for imgs, targets in loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(imgs)\n",
    "\n",
    "        if num_classes == 2:\n",
    "            targets_f = targets.float().unsqueeze(1)   # (N,1)\n",
    "            loss = criterion(logits, targets_f)\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).long().squeeze(1)\n",
    "        else:\n",
    "            loss = criterion(logits, targets)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "        total_loss += float(loss.item()) * imgs.size(0)\n",
    "        correct    += int((preds == targets).sum().item())\n",
    "        total      += int(imgs.size(0))\n",
    "\n",
    "    return total_loss / max(total, 1), correct / max(total, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34210ca8",
   "metadata": {},
   "source": [
    "Generic training loop (cosine schedule, early stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60cffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training loop with AdamW + CosineAnnealingLR + EarlyStopping ---\n",
    "\n",
    "def train_one_phase(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    num_classes: int,\n",
    "    epochs: int = 10,\n",
    "    lr: float = 1e-3,\n",
    "    weight_decay: float = 1e-2,\n",
    "    patience: int = 5,\n",
    "    pos_weight: Optional[float] = None,\n",
    "    label_smoothing: float = 0.05,\n",
    "    cosine_eta_min_scale: float = 0.01,\n",
    "    desc: str = \"Train\",\n",
    ") -> Tuple[nn.Module, float]:\n",
    "    # ----- Loss\n",
    "    if num_classes == 2:\n",
    "        criterion = nn.BCEWithLogitsLoss(\n",
    "            pos_weight=(torch.tensor([pos_weight], device=device) if pos_weight is not None else None)\n",
    "        )\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "    # ----- Optimizer over current trainable params only\n",
    "    trainable = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.AdamW(trainable, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # ----- Cosine LR schedule\n",
    "    eta_min = lr * cosine_eta_min_scale\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=eta_min)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    best_acc, best_state, no_improve = -1.0, None, 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total, correct, total_loss = 0, 0, 0.0\n",
    "\n",
    "        for imgs, targets in train_loader:\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
    "                logits = model(imgs)\n",
    "                if num_classes == 2:\n",
    "                    targets_f = targets.float().unsqueeze(1)\n",
    "                    loss = criterion(logits, targets_f)\n",
    "                    preds = (torch.sigmoid(logits) >= 0.5).long().squeeze(1)\n",
    "                else:\n",
    "                    loss = criterion(logits, targets)\n",
    "                    preds = logits.argmax(dim=1)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += float(loss.item()) * imgs.size(0)\n",
    "            correct    += int((preds == targets).sum().item())\n",
    "            total      += int(imgs.size(0))\n",
    "\n",
    "        scheduler.step()\n",
    "        train_loss = total_loss / max(total, 1)\n",
    "        train_acc  = correct / max(total, 1)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, device, num_classes)\n",
    "\n",
    "        print(f\"[{desc}] Epoch {epoch:03d}/{epochs} | \"\n",
    "              f\"train {train_loss:.4f}/{train_acc:.4f} | \"\n",
    "              f\"val {val_loss:.4f}/{val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"[{desc}] Early stopping (patience={patience}).\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state, strict=True)\n",
    "    return model, best_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d237559",
   "metadata": {},
   "source": [
    "Phase A: Train backbone only and save backbone-only checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f0aae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes (2): ['Negative', 'Positive']\n",
      "[Binary] Train counts: neg=1619, pos=253 → pos_weight=6.3992\n"
     ]
    }
   ],
   "source": [
    "# === PHASE 6 (alt): dataset + loaders with optional 80/20 split ===\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# ---- Config you may tweak ----\n",
    "DATA_DIR     = \"data\"   # parent folder; expects train/val OR single folder of class subdirs\n",
    "BATCH_SIZE   = 64\n",
    "WORKERS      = 4\n",
    "USE_AUG      = True\n",
    "SEED         = 42               # for deterministic split\n",
    "\n",
    "# ---- Transforms (aligned 224x224 crops; no resize/crop needed) ----\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "]) if USE_AUG else transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# ---- Dataset discovery ----\n",
    "data_dir  = Path(DATA_DIR)\n",
    "train_dir = data_dir / \"train\"\n",
    "val_dir   = data_dir / \"val\"\n",
    "\n",
    "if train_dir.is_dir() and val_dir.is_dir():\n",
    "    # Case A: explicit train/val subdirs\n",
    "    train_ds = datasets.ImageFolder(train_dir, transform=train_tfms)\n",
    "    val_ds   = datasets.ImageFolder(val_dir,   transform=val_tfms)\n",
    "else:\n",
    "    # Case B: single folder with class subdirs → split 80/20\n",
    "    full_ds  = datasets.ImageFolder(data_dir, transform=train_tfms)\n",
    "    n_val    = max(1, int(0.2 * len(full_ds)))\n",
    "    n_train  = len(full_ds) - n_val\n",
    "    train_ds, val_idx = random_split(\n",
    "        full_ds, [n_train, n_val],\n",
    "        generator=torch.Generator().manual_seed(SEED)\n",
    "    )\n",
    "    # Rebuild a val dataset that shares the same files but uses val transforms\n",
    "    val_ds = Subset(copy.deepcopy(full_ds), val_idx.indices)\n",
    "    val_ds.dataset.transform = val_tfms\n",
    "\n",
    "# ---- Class info ----\n",
    "classes = train_ds.dataset.classes if isinstance(train_ds, Subset) else train_ds.classes\n",
    "num_classes = len(classes)\n",
    "print(f\"Classes ({num_classes}): {classes}\")\n",
    "\n",
    "# ---- DataLoaders ----\n",
    "pin_mem = torch.cuda.is_available()\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=WORKERS, pin_memory=pin_mem)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=WORKERS, pin_memory=pin_mem)\n",
    "\n",
    "# ---- (Optional) compute pos_weight for binary imbalance (neg/pos) ----\n",
    "POS_WEIGHT = None\n",
    "if num_classes == 2:\n",
    "    # Count by scanning underlying dataset.samples\n",
    "    # Works for both Case A and Case B\n",
    "    def _count_samples(ds):\n",
    "        if isinstance(ds, Subset):\n",
    "            # ds.dataset is ImageFolder; ds.indices selects subset\n",
    "            labels = [ds.dataset.samples[i][1] for i in ds.indices]\n",
    "        else:\n",
    "            labels = [y for _, y in ds.samples]\n",
    "        neg = sum(1 for y in labels if y == 0)\n",
    "        pos = sum(1 for y in labels if y == 1)\n",
    "        return neg, pos\n",
    "\n",
    "    neg, pos = _count_samples(train_ds)\n",
    "    if pos > 0:\n",
    "        POS_WEIGHT = neg / float(pos)\n",
    "        print(f\"[Binary] Train counts: neg={neg}, pos={pos} → pos_weight={POS_WEIGHT:.4f}\")\n",
    "    else:\n",
    "        print(\"[Binary] WARNING: no positive samples in train set; pos_weight not set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a5c036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacky\\AppData\\Local\\Temp\\ipykernel_71900\\4176880697.py:34: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
      "C:\\Users\\jacky\\AppData\\Local\\Temp\\ipykernel_71900\\4176880697.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Backbone-only] Epoch 001/10 | train 0.5326/0.8686 | val 9.6868/0.3041\n",
      "[Backbone-only] Epoch 002/10 | train 0.2293/0.9647 | val 0.0892/0.9679\n",
      "[Backbone-only] Epoch 003/10 | train 0.0990/0.9840 | val 0.0690/0.9743\n",
      "[Backbone-only] Epoch 004/10 | train 0.0917/0.9840 | val 0.6385/0.8223\n",
      "[Backbone-only] Epoch 005/10 | train 0.0698/0.9904 | val 0.0828/0.9829\n",
      "[Backbone-only] Epoch 006/10 | train 0.0516/0.9915 | val 0.0483/0.9829\n",
      "[Backbone-only] Epoch 007/10 | train 0.0370/0.9963 | val 0.1074/0.9700\n",
      "[Backbone-only] Epoch 008/10 | train 0.0325/0.9963 | val 0.0230/0.9914\n",
      "[Backbone-only] Epoch 009/10 | train 0.0177/0.9984 | val 0.0234/0.9936\n",
      "[Backbone-only] Epoch 010/10 | train 0.0117/0.9989 | val 0.0245/0.9914\n",
      "Saved: outputs\\resnet18_backbone_only.pt | Best val acc: 0.9936\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR   = \"outputs\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "WORKERS    = 4\n",
    "EPOCHS_BACKBONE = 10\n",
    "LR_BACKBONE     = 1e-3\n",
    "WEIGHT_DECAY    = 1e-2\n",
    "PATIENCE        = 5\n",
    "LABEL_SMOOTHING = 0.05\n",
    "COSINE_ETA_MIN_SCALE = 0.01\n",
    "USE_AUG = True\n",
    "\n",
    "model = build_resnet18(num_classes)\n",
    "freeze_fc_only(model)\n",
    "model = model.to(device)\n",
    "\n",
    "# --- Train backbone only ---\n",
    "model, best_acc = train_one_phase(\n",
    "    model, train_loader, val_loader, device, num_classes,\n",
    "    epochs=EPOCHS_BACKBONE,\n",
    "    lr=LR_BACKBONE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    patience=PATIENCE,\n",
    "    pos_weight=POS_WEIGHT,\n",
    "    label_smoothing=LABEL_SMOOTHING,\n",
    "    cosine_eta_min_scale=COSINE_ETA_MIN_SCALE,\n",
    "    desc=\"Backbone-only\"\n",
    ")\n",
    "\n",
    "# --- Save backbone-only checkpoint (drops fc.*) ---\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "BACKBONE_CKPT = str(Path(OUT_DIR) / \"resnet18_backbone_only.pt\")\n",
    "save_backbone_only(model, BACKBONE_CKPT, img_size=224)\n",
    "print(\"Saved:\", BACKBONE_CKPT, \"| Best val acc:\", f\"{best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7653f35f",
   "metadata": {},
   "source": [
    "Phase B (step 1): Attach new head, warm-start by training head only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99ff070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_state_dict missing: ['fc.1.weight', 'fc.1.bias'] unexpected: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacky\\AppData\\Local\\Temp\\ipykernel_71900\\4176880697.py:34: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
      "C:\\Users\\jacky\\AppData\\Local\\Temp\\ipykernel_71900\\4176880697.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Head-only] Epoch 001/5 | train 0.1777/0.9583 | val 0.0256/0.9957\n",
      "[Head-only] Epoch 002/5 | train 0.0223/0.9989 | val 0.0203/0.9957\n",
      "[Head-only] Epoch 003/5 | train 0.0123/1.0000 | val 0.0189/0.9957\n",
      "[Head-only] Early stopping (patience=2).\n",
      "Best val acc (head-only): 0.9957\n"
     ]
    }
   ],
   "source": [
    "# === PHASE B-1: Load backbone-only ckpt, attach new head, train head-only ===\n",
    "# You can point TRAIN_DIR/VAL_DIR to a new dataset if desired.\n",
    "BACKBONE_CKPT = str(Path(OUT_DIR) / \"resnet18_backbone_only.pt\")\n",
    "\n",
    "# Rebuild base & head for current K\n",
    "model_ft = resnet18(weights=None)\n",
    "in_feats = model_ft.fc.in_features\n",
    "if num_classes == 2:\n",
    "    model_ft.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, 1))\n",
    "else:\n",
    "    model_ft.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, num_classes))\n",
    "\n",
    "# Load the backbone weights (fc.* are intentionally missing)\n",
    "ckpt = torch.load(BACKBONE_CKPT, map_location=\"cpu\")\n",
    "missing, unexpected = model_ft.load_state_dict(ckpt[\"state_dict\"], strict=False)\n",
    "print(\"load_state_dict missing:\", missing, \"unexpected:\", unexpected)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# --- Warm-start: head only ---\n",
    "for p in model_ft.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model_ft.fc.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "EPOCHS_HEAD = 5\n",
    "LR_HEAD     = 1e-3\n",
    "\n",
    "model_ft, best_acc_head = train_one_phase(\n",
    "    model_ft, train_loader, val_loader, device, num_classes,\n",
    "    epochs=EPOCHS_HEAD,\n",
    "    lr=LR_HEAD,\n",
    "    weight_decay=0.0,                 # usually no WD for small head\n",
    "    patience=max(2, PATIENCE // 2),\n",
    "    pos_weight=POS_WEIGHT,\n",
    "    label_smoothing=LABEL_SMOOTHING,\n",
    "    cosine_eta_min_scale=COSINE_ETA_MIN_SCALE,\n",
    "    desc=\"Head-only\"\n",
    ")\n",
    "\n",
    "print(\"Best val acc (head-only):\", f\"{best_acc_head:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c65b94",
   "metadata": {},
   "source": [
    "Phase B (step 2): Unfreeze backbone and fine-tune end-to-end (differential LRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a50c523a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacky\\AppData\\Local\\Temp\\ipykernel_71900\\814599089.py:26: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacky\\AppData\\Local\\Temp\\ipykernel_71900\\814599089.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Finetune] Epoch 001/10 | train 0.0171/0.9989 | val 0.0161/0.9936\n",
      "[Finetune] Epoch 002/10 | train 0.0040/0.9989 | val 0.0173/0.9957\n",
      "[Finetune] Epoch 003/10 | train 0.0023/1.0000 | val 0.0185/0.9936\n",
      "[Finetune] Epoch 004/10 | train 0.0044/1.0000 | val 0.0247/0.9872\n",
      "[Finetune] Epoch 005/10 | train 0.0037/0.9989 | val 0.0216/0.9914\n",
      "[Finetune] Epoch 006/10 | train 0.0013/1.0000 | val 0.0191/0.9936\n",
      "[Finetune] Epoch 007/10 | train 0.0013/1.0000 | val 0.0109/0.9936\n",
      "[Finetune] Early stopping (patience=5).\n",
      "Saved: outputs\\resnet18_finetuned_with_head.pt | Best val acc (finetune): 0.9957\n"
     ]
    }
   ],
   "source": [
    "# === PHASE B-2: Unfreeze backbone and fine-tune end-to-end ===\n",
    "\n",
    "for p in model_ft.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "LR_FINETUNE_HEAD     = 5e-4\n",
    "LR_FINETUNE_BACKBONE = 1e-4\n",
    "EPOCHS_FINETUNE      = 10\n",
    "\n",
    "# Build optimizer with differential LRs\n",
    "optim_params = [\n",
    "    {\"params\": (p for n,p in model_ft.named_parameters() if n.startswith(\"fc.\")),\n",
    "     \"lr\": LR_FINETUNE_HEAD, \"weight_decay\": 0.0},\n",
    "    {\"params\": (p for n,p in model_ft.named_parameters() if not n.startswith(\"fc.\")),\n",
    "     \"lr\": LR_FINETUNE_BACKBONE, \"weight_decay\": WEIGHT_DECAY},\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optim_params)\n",
    "\n",
    "# Loss for the fine-tune phase\n",
    "criterion_ft = (nn.BCEWithLogitsLoss(pos_weight=(torch.tensor([POS_WEIGHT], device=device) if (num_classes==2 and POS_WEIGHT is not None) else None))\n",
    "                if num_classes == 2\n",
    "                else nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING))\n",
    "\n",
    "eta_min = max(LR_FINETUNE_HEAD, LR_FINETUNE_BACKBONE) * COSINE_ETA_MIN_SCALE\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_FINETUNE, eta_min=eta_min)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "best_acc_finetune, best_state, no_improve = -1.0, None, 0\n",
    "\n",
    "print(\"Fine-tuning...\")\n",
    "for epoch in range(1, EPOCHS_FINETUNE + 1):\n",
    "    model_ft.train()\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "\n",
    "    for imgs, targets in train_loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
    "            logits = model_ft(imgs)\n",
    "            if num_classes == 2:\n",
    "                targets_f = targets.float().unsqueeze(1)\n",
    "                loss = criterion_ft(logits, targets_f)\n",
    "                preds = (torch.sigmoid(logits) >= 0.5).long().squeeze(1)\n",
    "            else:\n",
    "                loss = criterion_ft(logits, targets)\n",
    "                preds = logits.argmax(dim=1)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += float(loss.item()) * imgs.size(0)\n",
    "        correct    += int((preds == targets).sum().item())\n",
    "        total      += int(imgs.size(0))\n",
    "\n",
    "    scheduler.step()\n",
    "    train_loss = total_loss / max(total, 1)\n",
    "    train_acc  = correct / max(total, 1)\n",
    "\n",
    "    val_loss, val_acc = evaluate(model_ft, val_loader, device, num_classes)\n",
    "    print(f\"[Finetune] Epoch {epoch:03d}/{EPOCHS_FINETUNE} | \"\n",
    "          f\"train {train_loss:.4f}/{train_acc:.4f} | \"\n",
    "          f\"val {val_loss:.4f}/{val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_acc_finetune:\n",
    "        best_acc_finetune = val_acc\n",
    "        best_state = {k: v.cpu() for k, v in model_ft.state_dict().items()}\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= PATIENCE:\n",
    "            print(f\"[Finetune] Early stopping (patience={PATIENCE}).\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model_ft.load_state_dict(best_state, strict=True)\n",
    "\n",
    "FINAL_CKPT = str(Path(OUT_DIR) / \"resnet18_finetuned_with_head.pt\")\n",
    "torch.save(model_ft.state_dict(), FINAL_CKPT)\n",
    "print(\"Saved:\", FINAL_CKPT, \"| Best val acc (finetune):\", f\"{best_acc_finetune:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18496368",
   "metadata": {},
   "source": [
    "Inference helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ee06fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inference helper (binary & multiclass) ---\n",
    "from PIL import Image\n",
    "\n",
    "infer_tfms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "def predict_image(model: nn.Module, img_path: str, classes: List[str]) -> dict:\n",
    "    model.eval()\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = infer_tfms(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        if len(classes) == 2:\n",
    "            p = torch.sigmoid(logits).item()\n",
    "            pred_idx = int(p >= 0.5)\n",
    "            return {\"pred_idx\": pred_idx, \"pred_class\": classes[pred_idx], \"prob_positive\": float(p)}\n",
    "        else:\n",
    "            probs = torch.softmax(logits, dim=1).squeeze(0)\n",
    "            pred_idx = int(probs.argmax().item())\n",
    "            return {\"pred_idx\": pred_idx, \"pred_class\": classes[pred_idx], \"probs\": probs.cpu().tolist()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c662226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_idx': 1, 'pred_class': 'Positive', 'prob_positive': 0.7976053953170776}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image(model_ft, \"t/1.jpg\", classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
